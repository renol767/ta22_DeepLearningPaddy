{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "mhbh40buQZ5h",
    "outputId": "a18d1017-fd9f-4bf6-bb9b-e2419db53888"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_gpu==1.15.5\n",
      "  Downloading tensorflow_gpu-1.15.5-cp37-cp37m-manylinux2010_x86_64.whl (411.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 411.0 MB 25 kB/s \n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.5) (1.0.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.5) (1.1.0)\n",
      "Collecting tensorboard<1.16.0,>=1.15.0\n",
      "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 52.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.5) (1.1.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.5) (0.37.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.5) (0.8.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.5) (3.3.0)\n",
      "Collecting numpy<1.19.0,>=1.16.0\n",
      "  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.1 MB 1.1 MB/s \n",
      "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
      "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
      "\u001b[K     |████████████████████████████████| 503 kB 54.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.5) (1.15.0)\n",
      "Collecting h5py<=2.10.0\n",
      "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 56.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.5) (3.17.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.5) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.5) (1.14.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15.5) (1.44.0)\n",
      "Collecting gast==0.2.2\n",
      "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
      "Collecting keras-applications>=1.0.8\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 6.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15.5) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15.5) (57.4.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15.5) (3.3.6)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15.5) (4.11.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15.5) (3.10.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15.5) (3.7.0)\n",
      "Building wheels for collected packages: gast\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=1b67a1350f8752040d481cd519ca44689acfffdfe2810f4115a7eb7573eba05d\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
      "Successfully built gast\n",
      "Installing collected packages: numpy, h5py, tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow-gpu\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.5\n",
      "    Uninstalling numpy-1.21.5:\n",
      "      Successfully uninstalled numpy-1.21.5\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.1.0\n",
      "    Uninstalling h5py-3.1.0:\n",
      "      Successfully uninstalled h5py-3.1.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.8.0\n",
      "    Uninstalling tensorflow-estimator-2.8.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.8.0\n",
      "    Uninstalling tensorboard-2.8.0:\n",
      "      Successfully uninstalled tensorboard-2.8.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.5.3\n",
      "    Uninstalling gast-0.5.3:\n",
      "      Successfully uninstalled gast-0.5.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
      "tensorflow 2.8.0 requires numpy>=1.20, but you have numpy 1.18.5 which is incompatible.\n",
      "tensorflow 2.8.0 requires tensorboard<2.9,>=2.8, but you have tensorboard 1.15.0 which is incompatible.\n",
      "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
      "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.18.5 which is incompatible.\n",
      "jaxlib 0.3.2+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.18.5 which is incompatible.\n",
      "jax 0.3.4 requires numpy>=1.19, but you have numpy 1.18.5 which is incompatible.\n",
      "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
      "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Successfully installed gast-0.2.2 h5py-2.10.0 keras-applications-1.0.8 numpy-1.18.5 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "numpy"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install tensorflow_gpu==1.15.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iUEgpUNJTVVx",
    "outputId": "02521129-3bca-4b89-987c-e074ee8d35c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.18.5 in /usr/local/lib/python3.7/dist-packages (1.18.5)\n",
      "Found existing installation: pycocotools 2.0.4\n",
      "Uninstalling pycocotools-2.0.4:\n",
      "  Successfully uninstalled pycocotools-2.0.4\n",
      "Collecting pycocotools\n",
      "  Downloading pycocotools-2.0.4.tar.gz (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 8.9 MB/s \n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pycocotools) (1.18.5)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools) (3.2.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.0.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.0->pycocotools) (3.10.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools) (1.15.0)\n",
      "Building wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pycocotools: filename=pycocotools-2.0.4-cp37-cp37m-linux_x86_64.whl size=265221 sha256=13f65d8291443fcc24fcf1172a3fb4e71349220428bc66d8dd4c954614effb05\n",
      "  Stored in directory: /root/.cache/pip/wheels/a3/5f/fa/f011e578cc76e1fc5be8dce30b3eb9fd00f337e744b3bba59b\n",
      "Successfully built pycocotools\n",
      "Installing collected packages: pycocotools\n",
      "Successfully installed pycocotools-2.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.18.5\n",
    "!pip uninstall -y pycocotools\n",
    "!pip install pycocotools --no-binary pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0a3UWdOJPKO",
    "outputId": "8bcf9da8-fa1d-44f7-83c5-b7480f06a39f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n"
     ]
    }
   ],
   "source": [
    "# use TF 1.x\n",
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eAD5-ZrGQnI4",
    "outputId": "2e5bd370-50fc-4909-85de-fb486bb7edeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version\n",
      "----------------------------- ---------------------\n",
      "absl-py                       1.0.0\n",
      "alabaster                     0.7.12\n",
      "albumentations                0.1.12\n",
      "altair                        4.2.0\n",
      "appdirs                       1.4.4\n",
      "argon2-cffi                   21.3.0\n",
      "argon2-cffi-bindings          21.2.0\n",
      "arviz                         0.11.4\n",
      "astor                         0.8.1\n",
      "astropy                       4.3.1\n",
      "astunparse                    1.6.3\n",
      "atari-py                      0.2.9\n",
      "atomicwrites                  1.4.0\n",
      "attrs                         21.4.0\n",
      "audioread                     2.1.9\n",
      "autograd                      1.3\n",
      "Babel                         2.9.1\n",
      "backcall                      0.2.0\n",
      "backports.tempfile            1.0\n",
      "backports.weakref             1.0.post1\n",
      "beautifulsoup4                4.6.3\n",
      "bleach                        4.1.0\n",
      "blis                          0.4.1\n",
      "bokeh                         2.3.3\n",
      "Bottleneck                    1.3.4\n",
      "branca                        0.4.2\n",
      "bs4                           0.0.1\n",
      "bz2file                       0.98\n",
      "CacheControl                  0.12.10\n",
      "cached-property               1.5.2\n",
      "cachetools                    4.2.4\n",
      "catalogue                     1.0.0\n",
      "certifi                       2021.10.8\n",
      "cffi                          1.15.0\n",
      "cftime                        1.6.0\n",
      "chardet                       3.0.4\n",
      "charset-normalizer            2.0.12\n",
      "click                         7.1.2\n",
      "cloudpickle                   1.3.0\n",
      "cmake                         3.12.0\n",
      "cmdstanpy                     0.9.5\n",
      "colorcet                      3.0.0\n",
      "colorlover                    0.3.0\n",
      "community                     1.0.0b1\n",
      "contextlib2                   0.5.5\n",
      "convertdate                   2.4.0\n",
      "coverage                      3.7.1\n",
      "coveralls                     0.5\n",
      "crcmod                        1.7\n",
      "cufflinks                     0.17.3\n",
      "cupy-cuda111                  9.4.0\n",
      "cvxopt                        1.2.7\n",
      "cvxpy                         1.0.31\n",
      "cycler                        0.11.0\n",
      "cymem                         2.0.6\n",
      "Cython                        0.29.28\n",
      "daft                          0.0.4\n",
      "dask                          2.12.0\n",
      "datascience                   0.10.6\n",
      "debugpy                       1.0.0\n",
      "decorator                     4.4.2\n",
      "defusedxml                    0.7.1\n",
      "descartes                     1.1.0\n",
      "dill                          0.3.4\n",
      "distributed                   1.25.3\n",
      "dlib                          19.18.0\n",
      "dm-sonnet                     1.35\n",
      "dm-tree                       0.1.6\n",
      "docopt                        0.6.2\n",
      "docutils                      0.17.1\n",
      "dopamine-rl                   1.0.5\n",
      "earthengine-api               0.1.303\n",
      "easydict                      1.9\n",
      "ecos                          2.0.10\n",
      "editdistance                  0.5.3\n",
      "en-core-web-sm                2.2.5\n",
      "entrypoints                   0.4\n",
      "ephem                         4.1.3\n",
      "et-xmlfile                    1.1.0\n",
      "fa2                           0.3.5\n",
      "fastai                        1.0.61\n",
      "fastdtw                       0.3.4\n",
      "fastprogress                  1.0.2\n",
      "fastrlock                     0.8\n",
      "fbprophet                     0.7.1\n",
      "feather-format                0.4.1\n",
      "filelock                      3.6.0\n",
      "firebase-admin                4.4.0\n",
      "fix-yahoo-finance             0.0.22\n",
      "Flask                         1.1.4\n",
      "flatbuffers                   2.0\n",
      "folium                        0.8.3\n",
      "future                        0.16.0\n",
      "gast                          0.2.2\n",
      "GDAL                          2.2.2\n",
      "gdown                         4.2.2\n",
      "gensim                        3.6.0\n",
      "geographiclib                 1.52\n",
      "geopy                         1.17.0\n",
      "gevent                        1.4.0\n",
      "gin-config                    0.5.0\n",
      "glob2                         0.7\n",
      "google                        2.0.3\n",
      "google-api-core               1.26.3\n",
      "google-api-python-client      1.12.11\n",
      "google-auth                   1.35.0\n",
      "google-auth-httplib2          0.0.4\n",
      "google-auth-oauthlib          0.4.6\n",
      "google-cloud-bigquery         1.21.0\n",
      "google-cloud-bigquery-storage 1.1.0\n",
      "google-cloud-core             1.0.3\n",
      "google-cloud-datastore        1.8.0\n",
      "google-cloud-firestore        1.7.0\n",
      "google-cloud-language         1.2.0\n",
      "google-cloud-storage          1.18.1\n",
      "google-cloud-translate        1.5.0\n",
      "google-colab                  1.0.0\n",
      "google-pasta                  0.2.0\n",
      "google-resumable-media        0.4.1\n",
      "googleapis-common-protos      1.56.0\n",
      "googledrivedownloader         0.4\n",
      "graph-nets                    1.0.5\n",
      "graphviz                      0.10.1\n",
      "greenlet                      0.4.15\n",
      "grpcio                        1.44.0\n",
      "gspread                       3.4.2\n",
      "gspread-dataframe             3.0.8\n",
      "gunicorn                      20.0.4\n",
      "gym                           0.17.3\n",
      "h5py                          2.10.0\n",
      "HeapDict                      1.0.1\n",
      "hijri-converter               2.2.3\n",
      "holidays                      0.10.5.2\n",
      "holoviews                     1.14.8\n",
      "html5lib                      1.0.1\n",
      "httpimport                    0.5.18\n",
      "httplib2                      0.17.4\n",
      "httplib2shim                  0.0.3\n",
      "humanize                      0.5.1\n",
      "hyperopt                      0.1.2\n",
      "ideep4py                      2.0.0.post3\n",
      "idna                          2.10\n",
      "imageio                       2.4.1\n",
      "imagesize                     1.3.0\n",
      "imbalanced-learn              0.8.1\n",
      "imblearn                      0.0\n",
      "imgaug                        0.2.9\n",
      "importlib-metadata            4.11.3\n",
      "importlib-resources           5.4.0\n",
      "imutils                       0.5.4\n",
      "inflect                       2.1.0\n",
      "iniconfig                     1.1.1\n",
      "intel-openmp                  2022.0.2\n",
      "intervaltree                  2.1.0\n",
      "ipykernel                     4.10.1\n",
      "ipython                       5.5.0\n",
      "ipython-genutils              0.2.0\n",
      "ipython-sql                   0.3.9\n",
      "ipywidgets                    7.7.0\n",
      "itsdangerous                  1.1.0\n",
      "jax                           0.3.4\n",
      "jaxlib                        0.3.2+cuda11.cudnn805\n",
      "jedi                          0.18.1\n",
      "jieba                         0.42.1\n",
      "Jinja2                        2.11.3\n",
      "joblib                        1.1.0\n",
      "jpeg4py                       0.1.4\n",
      "jsonschema                    4.3.3\n",
      "jupyter                       1.0.0\n",
      "jupyter-client                5.3.5\n",
      "jupyter-console               5.2.0\n",
      "jupyter-core                  4.9.2\n",
      "jupyterlab-pygments           0.1.2\n",
      "jupyterlab-widgets            1.1.0\n",
      "kaggle                        1.5.12\n",
      "kapre                         0.3.7\n",
      "Keras                         2.3.1\n",
      "Keras-Applications            1.0.8\n",
      "Keras-Preprocessing           1.1.2\n",
      "keras-vis                     0.4.1\n",
      "kfac                          0.2.0\n",
      "kiwisolver                    1.4.0\n",
      "korean-lunar-calendar         0.2.1\n",
      "libclang                      13.0.0\n",
      "librosa                       0.8.1\n",
      "lightgbm                      2.2.3\n",
      "llvmlite                      0.34.0\n",
      "lmdb                          0.99\n",
      "lucid                         0.3.10\n",
      "LunarCalendar                 0.0.9\n",
      "lxml                          4.2.6\n",
      "magenta                       0.3.19\n",
      "Markdown                      3.3.6\n",
      "MarkupSafe                    2.0.1\n",
      "matplotlib                    3.2.2\n",
      "matplotlib-inline             0.1.3\n",
      "matplotlib-venn               0.11.6\n",
      "mesh-tensorflow               0.1.12\n",
      "mido                          1.2.6\n",
      "mir-eval                      0.5\n",
      "missingno                     0.5.1\n",
      "mistune                       0.8.4\n",
      "mizani                        0.6.0\n",
      "mkl                           2019.0\n",
      "mlxtend                       0.14.0\n",
      "more-itertools                8.12.0\n",
      "moviepy                       0.2.3.5\n",
      "mpi4py                        3.0.3\n",
      "mpmath                        1.2.1\n",
      "msgpack                       1.0.3\n",
      "multiprocess                  0.70.12.2\n",
      "multitasking                  0.0.10\n",
      "murmurhash                    1.0.6\n",
      "music21                       5.5.0\n",
      "natsort                       5.5.0\n",
      "nbclient                      0.5.13\n",
      "nbconvert                     5.6.1\n",
      "nbformat                      5.2.0\n",
      "nest-asyncio                  1.5.4\n",
      "netCDF4                       1.5.8\n",
      "networkx                      2.6.3\n",
      "nibabel                       3.0.2\n",
      "nltk                          3.2.5\n",
      "notebook                      5.3.1\n",
      "numba                         0.51.2\n",
      "numexpr                       2.8.1\n",
      "numpy                         1.18.5\n",
      "nvidia-ml-py3                 7.352.0\n",
      "oauth2client                  4.1.3\n",
      "oauthlib                      3.2.0\n",
      "okgrade                       0.4.3\n",
      "opencv-contrib-python         4.1.2.30\n",
      "opencv-python                 4.1.2.30\n",
      "openpyxl                      3.0.9\n",
      "opt-einsum                    3.3.0\n",
      "osqp                          0.6.2.post0\n",
      "packaging                     21.3\n",
      "palettable                    3.3.0\n",
      "pandas                        1.3.5\n",
      "pandas-datareader             0.9.0\n",
      "pandas-gbq                    0.13.3\n",
      "pandas-profiling              1.4.1\n",
      "pandocfilters                 1.5.0\n",
      "panel                         0.12.1\n",
      "param                         1.12.0\n",
      "parso                         0.8.3\n",
      "pathlib                       1.0.1\n",
      "patsy                         0.5.2\n",
      "pep517                        0.12.0\n",
      "pexpect                       4.8.0\n",
      "pickleshare                   0.7.5\n",
      "Pillow                        7.1.2\n",
      "pip                           21.1.3\n",
      "pip-tools                     6.2.0\n",
      "plac                          1.1.3\n",
      "plotly                        5.5.0\n",
      "plotnine                      0.6.0\n",
      "pluggy                        0.7.1\n",
      "pooch                         1.6.0\n",
      "portpicker                    1.3.9\n",
      "prefetch-generator            1.0.1\n",
      "preshed                       3.0.6\n",
      "pretty-midi                   0.2.8\n",
      "prettytable                   3.2.0\n",
      "progressbar2                  3.38.0\n",
      "prometheus-client             0.13.1\n",
      "promise                       2.3\n",
      "prompt-toolkit                1.0.18\n",
      "protobuf                      3.17.3\n",
      "psutil                        5.4.8\n",
      "psycopg2                      2.7.6.1\n",
      "ptyprocess                    0.7.0\n",
      "py                            1.11.0\n",
      "pyarrow                       6.0.1\n",
      "pyasn1                        0.4.8\n",
      "pyasn1-modules                0.2.8\n",
      "pycocotools                   2.0.4\n",
      "pycparser                     2.21\n",
      "pyct                          0.4.8\n",
      "pydata-google-auth            1.4.0\n",
      "pydot                         1.3.0\n",
      "pydot-ng                      2.0.0\n",
      "pydotplus                     2.0.2\n",
      "PyDrive                       1.3.1\n",
      "pyemd                         0.5.1\n",
      "pyerfa                        2.0.0.1\n",
      "pyglet                        1.5.0\n",
      "Pygments                      2.6.1\n",
      "pygobject                     3.26.1\n",
      "pymc3                         3.11.4\n",
      "PyMeeus                       0.5.11\n",
      "pymongo                       4.0.2\n",
      "pymystem3                     0.2.0\n",
      "PyOpenGL                      3.1.6\n",
      "pyparsing                     3.0.7\n",
      "pypng                         0.0.20\n",
      "pyrsistent                    0.18.1\n",
      "pysndfile                     1.3.8\n",
      "PySocks                       1.7.1\n",
      "pystan                        2.19.1.1\n",
      "pytest                        3.6.4\n",
      "python-apt                    0.0.0\n",
      "python-chess                  0.23.11\n",
      "python-dateutil               2.8.2\n",
      "python-louvain                0.16\n",
      "python-rtmidi                 1.4.0\n",
      "python-slugify                6.1.1\n",
      "python-utils                  3.1.0\n",
      "pytz                          2018.9\n",
      "pyviz-comms                   2.1.0\n",
      "PyWavelets                    1.3.0\n",
      "PyYAML                        3.13\n",
      "pyzmq                         22.3.0\n",
      "qdldl                         0.1.5.post0\n",
      "qtconsole                     5.2.2\n",
      "QtPy                          2.0.1\n",
      "regex                         2019.12.20\n",
      "requests                      2.23.0\n",
      "requests-oauthlib             1.3.1\n",
      "resampy                       0.2.2\n",
      "rpy2                          3.4.5\n",
      "rsa                           4.8\n",
      "scikit-image                  0.18.3\n",
      "scikit-learn                  1.0.2\n",
      "scipy                         1.4.1\n",
      "screen-resolution-extra       0.0.0\n",
      "scs                           3.2.0\n",
      "seaborn                       0.11.2\n",
      "semantic-version              2.8.4\n",
      "semver                        2.13.0\n",
      "Send2Trash                    1.8.0\n",
      "setuptools                    57.4.0\n",
      "setuptools-git                1.2\n",
      "Shapely                       1.8.1.post1\n",
      "simplegeneric                 0.8.1\n",
      "six                           1.15.0\n",
      "sklearn                       0.0\n",
      "sklearn-pandas                1.8.0\n",
      "smart-open                    5.2.1\n",
      "snowballstemmer               2.2.0\n",
      "sortedcontainers              2.4.0\n",
      "SoundFile                     0.10.3.post1\n",
      "soupsieve                     2.3.1\n",
      "spacy                         2.2.4\n",
      "Sphinx                        1.8.6\n",
      "sphinxcontrib-serializinghtml 1.1.5\n",
      "sphinxcontrib-websupport      1.2.4\n",
      "SQLAlchemy                    1.4.32\n",
      "sqlparse                      0.4.2\n",
      "srsly                         1.0.5\n",
      "stable-baselines              2.2.1\n",
      "statsmodels                   0.10.2\n",
      "sympy                         1.7.1\n",
      "tables                        3.7.0\n",
      "tabulate                      0.8.9\n",
      "tblib                         1.7.0\n",
      "tenacity                      8.0.1\n",
      "tensor2tensor                 1.14.1\n",
      "tensorboard                   1.15.0\n",
      "tensorboard-data-server       0.6.1\n",
      "tensorboard-plugin-wit        1.8.1\n",
      "tensorflow                    1.15.2\n",
      "tensorflow-datasets           4.0.1\n",
      "tensorflow-estimator          1.15.1\n",
      "tensorflow-gan                2.0.0\n",
      "tensorflow-gcs-config         2.8.0\n",
      "tensorflow-gpu                1.15.5\n",
      "tensorflow-hub                0.12.0\n",
      "tensorflow-io-gcs-filesystem  0.24.0\n",
      "tensorflow-metadata           1.7.0\n",
      "tensorflow-probability        0.7.0\n",
      "termcolor                     1.1.0\n",
      "terminado                     0.13.3\n",
      "testpath                      0.6.0\n",
      "text-unidecode                1.3\n",
      "textblob                      0.15.3\n",
      "tflearn                       0.3.2\n",
      "Theano-PyMC                   1.1.2\n",
      "thinc                         7.4.0\n",
      "threadpoolctl                 3.1.0\n",
      "tifffile                      2021.11.2\n",
      "tomli                         2.0.1\n",
      "toolz                         0.11.2\n",
      "torch                         1.10.0+cu111\n",
      "torchaudio                    0.10.0+cu111\n",
      "torchsummary                  1.5.1\n",
      "torchtext                     0.11.0\n",
      "torchvision                   0.11.1+cu111\n",
      "tornado                       5.1.1\n",
      "tqdm                          4.63.0\n",
      "traitlets                     5.1.1\n",
      "tweepy                        3.10.0\n",
      "typeguard                     2.7.1\n",
      "typing-extensions             3.10.0.2\n",
      "tzlocal                       1.5.1\n",
      "uritemplate                   3.0.1\n",
      "urllib3                       1.24.3\n",
      "vega-datasets                 0.9.0\n",
      "wasabi                        0.9.0\n",
      "wcwidth                       0.2.5\n",
      "webencodings                  0.5.1\n",
      "Werkzeug                      1.0.1\n",
      "wheel                         0.37.1\n",
      "widgetsnbextension            3.6.0\n",
      "wordcloud                     1.5.0\n",
      "wrapt                         1.14.0\n",
      "xarray                        0.18.2\n",
      "xgboost                       0.90\n",
      "xkit                          0.0.0\n",
      "xlrd                          1.1.0\n",
      "xlwt                          1.3.0\n",
      "yellowbrick                   1.4\n",
      "zict                          2.1.0\n",
      "zipp                          3.7.0\n",
      "zmq                           0.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6wJrTWKJOLE"
   },
   "outputs": [],
   "source": [
    "# If you forked the repo, you can replace the link.\n",
    "repo_url = 'https://github.com/roboflow-ai/tensorflow-object-detection-faster-rcnn'\n",
    "\n",
    "# Number of training steps - 1000 will train very quickly, but more steps will increase accuracy.\n",
    "num_steps = 500  # 200000 to improve\n",
    "\n",
    "# Number of evaluation steps.\n",
    "num_eval_steps = 100\n",
    "\n",
    "MODELS_CONFIG = {\n",
    "    'ssd_mobilenet_v2': {\n",
    "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
    "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
    "        'batch_size': 16\n",
    "    },\n",
    "    'faster_rcnn_inception_v2': {\n",
    "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
    "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
    "        'batch_size': 12\n",
    "    },\n",
    "    'rfcn_resnet101': {\n",
    "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
    "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
    "        'batch_size': 8\n",
    "    }\n",
    "}\n",
    "\n",
    "# Pick the model you want to use\n",
    "# Select a model in `MODELS_CONFIG`.\n",
    "selected_model = 'ssd_mobilenet_v2'\n",
    "\n",
    "# Name of the object detection model to use.\n",
    "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
    "\n",
    "# Name of the pipline file in tensorflow object detection API.\n",
    "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
    "\n",
    "# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n",
    "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wxd6WwQwJh_d",
    "outputId": "43797098-3dcb-4e61-f38f-9b7ee0cb17d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "Cloning into 'tensorflow-object-detection-faster-rcnn'...\n",
      "remote: Enumerating objects: 885, done.\u001b[K\n",
      "remote: Total 885 (delta 0), reused 0 (delta 0), pack-reused 885\u001b[K\n",
      "Receiving objects: 100% (885/885), 24.83 MiB | 30.20 MiB/s, done.\n",
      "Resolving deltas: 100% (428/428), done.\n",
      "/content/tensorflow-object-detection-faster-rcnn\n",
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "%cd /content\n",
    "\n",
    "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
    "\n",
    "!git clone {repo_url}\n",
    "%cd {repo_dir_path}\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wr1dJ9L1Jlm1",
    "outputId": "9a1e4fe1-8c22-4dd3-c704-1b222b926a16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "Collecting tf_slim\n",
      "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "\u001b[K     |████████████████████████████████| 352 kB 7.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (1.0.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
      "Installing collected packages: tf-slim\n",
      "Successfully installed tf-slim-1.1.0\n",
      "Selecting previously unselected package python-bs4.\n",
      "(Reading database ... 156210 files and directories currently installed.)\n",
      "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
      "Unpacking python-bs4 (4.6.0-1) ...\n",
      "Selecting previously unselected package python-pkg-resources.\n",
      "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
      "Unpacking python-pkg-resources (39.0.1-2) ...\n",
      "Selecting previously unselected package python-chardet.\n",
      "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
      "Unpacking python-chardet (3.0.4-1) ...\n",
      "Selecting previously unselected package python-six.\n",
      "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
      "Unpacking python-six (1.11.0-2) ...\n",
      "Selecting previously unselected package python-webencodings.\n",
      "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
      "Unpacking python-webencodings (0.5-2) ...\n",
      "Selecting previously unselected package python-html5lib.\n",
      "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
      "Unpacking python-html5lib (0.999999999-1) ...\n",
      "Selecting previously unselected package python-lxml:amd64.\n",
      "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.6_amd64.deb ...\n",
      "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.6) ...\n",
      "Selecting previously unselected package python-olefile.\n",
      "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
      "Unpacking python-olefile (0.45.1-1) ...\n",
      "Selecting previously unselected package python-pil:amd64.\n",
      "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.7_amd64.deb ...\n",
      "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.7) ...\n",
      "Setting up python-pkg-resources (39.0.1-2) ...\n",
      "Setting up python-six (1.11.0-2) ...\n",
      "Setting up python-bs4 (4.6.0-1) ...\n",
      "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.6) ...\n",
      "Setting up python-olefile (0.45.1-1) ...\n",
      "Setting up python-pil:amd64 (5.1.0-1ubuntu0.7) ...\n",
      "Setting up python-webencodings (0.5-2) ...\n",
      "Setting up python-chardet (3.0.4-1) ...\n",
      "Setting up python-html5lib (0.999999999-1) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Collecting lvis\n",
      "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.11.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.15.0)\n",
      "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.4.0)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.18.5)\n",
      "Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (3.0.7)\n",
      "Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.29.28)\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis) (4.1.2.30)\n",
      "Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from lvis) (3.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.1.0->lvis) (3.10.0.2)\n",
      "Installing collected packages: lvis\n",
      "Successfully installed lvis-0.5.3\n",
      "/content/models/research\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%cd /content\n",
    "!git clone --quiet https://github.com/tensorflow/models.git\n",
    "\n",
    "!pip install tf_slim\n",
    "\n",
    "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
    "\n",
    "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
    "\n",
    "!pip install -q pycocotools\n",
    "\n",
    "!pip install lvis\n",
    "\n",
    "%cd /content/models/research\n",
    "!protoc object_detection/protos/*.proto --python_out=.\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
    "\n",
    "!python object_detection/builders/model_builder_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7BacjVVyLP53"
   },
   "outputs": [],
   "source": [
    "!unzip -q /content/drive/MyDrive/ssddataset.zip -d /content/tensorflow-object-detection-faster-rcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NjZsTxvSKxl1"
   },
   "outputs": [],
   "source": [
    "!unzip -q /content/drive/MyDrive/dataujissd.zip -d /content/tensorflow-object-detection-faster-rcnn/datauji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8RQa8fg5LvTM",
    "outputId": "1d035d26-d349-4c27-ab05-5e466598bcd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: /content/tensorflow-object-detection-faster-rcnn/data/train.record\n"
     ]
    }
   ],
   "source": [
    "# Create train data:\n",
    "!python /content/generate_tfrecord.py -x /content/tensorflow-object-detection-faster-rcnn/ssddataset/train -l /content/tensorflow-object-detection-faster-rcnn/data/label_map.pbtxt -o /content/tensorflow-object-detection-faster-rcnn/data/train.record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ksFODF0LMFmG",
    "outputId": "716f58cf-1c80-4fb8-f285-7acfb40b8e75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: /content/tensorflow-object-detection-faster-rcnn/data/test.record\n"
     ]
    }
   ],
   "source": [
    "# Create test data:\n",
    "!python /content/generate_tfrecord.py -x /content/tensorflow-object-detection-faster-rcnn/ssddataset/test -l /content/tensorflow-object-detection-faster-rcnn/data/label_map.pbtxt -o /content/tensorflow-object-detection-faster-rcnn/data/test.record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5A1MQB4uMNfA"
   },
   "outputs": [],
   "source": [
    "test_record_fname = '/content/tensorflow-object-detection-faster-rcnn/data/test.record'\n",
    "train_record_fname = '/content/tensorflow-object-detection-faster-rcnn/data/train.record'\n",
    "label_map_pbtxt_fname = '/content/tensorflow-object-detection-faster-rcnn/data/label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "I203qKmFMvgR",
    "outputId": "44fa3ae1-1d37-4b3b-a5b4-3bc4664c0cfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/models/research\n",
      "/content/models/research/pretrained_model\n",
      "total 135M\n",
      "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 .\n",
      "drwxr-xr-x 23 root   root  4.0K Apr  7 01:33 ..\n",
      "-rw-r--r--  1 345018 89939   77 Mar 30  2018 checkpoint\n",
      "-rw-r--r--  1 345018 89939  67M Mar 30  2018 frozen_inference_graph.pb\n",
      "-rw-r--r--  1 345018 89939  65M Mar 30  2018 model.ckpt.data-00000-of-00001\n",
      "-rw-r--r--  1 345018 89939  15K Mar 30  2018 model.ckpt.index\n",
      "-rw-r--r--  1 345018 89939 3.4M Mar 30  2018 model.ckpt.meta\n",
      "-rw-r--r--  1 345018 89939 4.2K Mar 30  2018 pipeline.config\n",
      "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 saved_model\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/models/research/pretrained_model/model.ckpt'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /content/models/research\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import urllib.request\n",
    "import tarfile\n",
    "MODEL_FILE = MODEL + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "DEST_DIR = '/content/models/research/pretrained_model'\n",
    "\n",
    "if not (os.path.exists(MODEL_FILE)):\n",
    "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "\n",
    "tar = tarfile.open(MODEL_FILE)\n",
    "tar.extractall()\n",
    "tar.close()\n",
    "\n",
    "os.remove(MODEL_FILE)\n",
    "if (os.path.exists(DEST_DIR)):\n",
    "    shutil.rmtree(DEST_DIR)\n",
    "os.rename(MODEL, DEST_DIR)\n",
    "\n",
    "!echo {DEST_DIR}\n",
    "!ls -alh {DEST_DIR}\n",
    "\n",
    "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
    "fine_tune_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dSdG_ThhMyo_",
    "outputId": "2b1d4283-c93c-464c-dc86-ea79c8017e4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# SSD with Mobilenet v2 configuration for MSCOCO Dataset.\n",
      "# Users should configure the fine_tune_checkpoint field in the train config as\n",
      "# well as the label_map_path and input_path fields in the train_input_reader and\n",
      "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
      "# should be configured.\n",
      "\n",
      "model {\n",
      "  ssd {\n",
      "    num_classes: 2\n",
      "    box_coder {\n",
      "      faster_rcnn_box_coder {\n",
      "        y_scale: 10.0\n",
      "        x_scale: 10.0\n",
      "        height_scale: 5.0\n",
      "        width_scale: 5.0\n",
      "      }\n",
      "    }\n",
      "    matcher {\n",
      "      argmax_matcher {\n",
      "        matched_threshold: 0.5\n",
      "        unmatched_threshold: 0.5\n",
      "        ignore_thresholds: false\n",
      "        negatives_lower_than_unmatched: true\n",
      "        force_match_for_each_row: true\n",
      "      }\n",
      "    }\n",
      "    similarity_calculator {\n",
      "      iou_similarity {\n",
      "      }\n",
      "    }\n",
      "    anchor_generator {\n",
      "      ssd_anchor_generator {\n",
      "        num_layers: 6\n",
      "        min_scale: 0.2\n",
      "        max_scale: 0.95\n",
      "        aspect_ratios: 1.0\n",
      "        aspect_ratios: 2.0\n",
      "        aspect_ratios: 0.5\n",
      "        aspect_ratios: 3.0\n",
      "        aspect_ratios: 0.3333\n",
      "      }\n",
      "    }\n",
      "    image_resizer {\n",
      "      fixed_shape_resizer {\n",
      "        height: 300\n",
      "        width: 300\n",
      "      }\n",
      "    }\n",
      "    box_predictor {\n",
      "      convolutional_box_predictor {\n",
      "        min_depth: 0\n",
      "        max_depth: 0\n",
      "        num_layers_before_predictor: 0\n",
      "        use_dropout: false\n",
      "        dropout_keep_probability: 0.8\n",
      "        kernel_size: 1\n",
      "        box_code_size: 4\n",
      "        apply_sigmoid_to_scores: false\n",
      "        conv_hyperparams {\n",
      "          activation: RELU_6,\n",
      "          regularizer {\n",
      "            l2_regularizer {\n",
      "              weight: 0.00004\n",
      "            }\n",
      "          }\n",
      "          initializer {\n",
      "            truncated_normal_initializer {\n",
      "              stddev: 0.03\n",
      "              mean: 0.0\n",
      "            }\n",
      "          }\n",
      "          batch_norm {\n",
      "            train: true,\n",
      "            scale: true,\n",
      "            center: true,\n",
      "            decay: 0.9997,\n",
      "            epsilon: 0.001,\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    feature_extractor {\n",
      "      type: 'ssd_mobilenet_v2'\n",
      "      min_depth: 16\n",
      "      depth_multiplier: 1.0\n",
      "      conv_hyperparams {\n",
      "        activation: RELU_6,\n",
      "        regularizer {\n",
      "          l2_regularizer {\n",
      "            weight: 0.00004\n",
      "          }\n",
      "        }\n",
      "        initializer {\n",
      "          truncated_normal_initializer {\n",
      "            stddev: 0.03\n",
      "            mean: 0.0\n",
      "          }\n",
      "        }\n",
      "        batch_norm {\n",
      "          train: true,\n",
      "          scale: true,\n",
      "          center: true,\n",
      "          decay: 0.9997,\n",
      "          epsilon: 0.001,\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    loss {\n",
      "      classification_loss {\n",
      "        weighted_sigmoid {\n",
      "        }\n",
      "      }\n",
      "      localization_loss {\n",
      "        weighted_smooth_l1 {\n",
      "        }\n",
      "      }\n",
      "      hard_example_miner {\n",
      "        num_hard_examples: 3000\n",
      "        iou_threshold: 0.99\n",
      "        loss_type: CLASSIFICATION\n",
      "        max_negatives_per_positive: 3\n",
      "        min_negatives_per_image: 3\n",
      "      }\n",
      "      classification_weight: 1.0\n",
      "      localization_weight: 1.0\n",
      "    }\n",
      "    normalize_loss_by_num_matches: true\n",
      "    post_processing {\n",
      "      batch_non_max_suppression {\n",
      "        score_threshold: 1e-8\n",
      "        iou_threshold: 0.6\n",
      "        max_detections_per_class: 100\n",
      "        max_total_detections: 100\n",
      "      }\n",
      "      score_converter: SIGMOID\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "train_config: {\n",
      "  batch_size: 16\n",
      "  optimizer {\n",
      "    rms_prop_optimizer: {\n",
      "      learning_rate: {\n",
      "        exponential_decay_learning_rate {\n",
      "          initial_learning_rate: 0.004\n",
      "          decay_steps: 800720\n",
      "          decay_factor: 0.95\n",
      "        }\n",
      "      }\n",
      "      momentum_optimizer_value: 0.9\n",
      "      decay: 0.9\n",
      "      epsilon: 1.0\n",
      "    }\n",
      "  }\n",
      "  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n",
      "  fine_tune_checkpoint_type:  \"detection\"\n",
      "  # Note: The below line limits the training process to 200K steps, which we\n",
      "  # empirically found to be sufficient enough to train the pets dataset. This\n",
      "  # effectively bypasses the learning rate schedule (the learning rate will\n",
      "  # never decay). Remove the below line to train indefinitely.\n",
      "  num_steps: 500\n",
      "  data_augmentation_options {\n",
      "    random_horizontal_flip {\n",
      "    }\n",
      "  }\n",
      "  data_augmentation_options {\n",
      "    ssd_random_crop {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "train_input_reader: {\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train.record\"\n",
      "  }\n",
      "  label_map_path: \"/content/tensorflow-object-detection-faster-rcnn/data/label_map.pbtxt\"\n",
      "}\n",
      "\n",
      "eval_config: {\n",
      "  num_examples: 8000\n",
      "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
      "  # Remove the below line to evaluate indefinitely.\n",
      "  max_evals: 10\n",
      "}\n",
      "\n",
      "eval_input_reader: {\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"/content/tensorflow-object-detection-faster-rcnn/data/test.record\"\n",
      "  }\n",
      "  label_map_path: \"/content/tensorflow-object-detection-faster-rcnn/data/label_map.pbtxt\"\n",
      "  shuffle: false\n",
      "  num_readers: 1\n",
      "}"
     ]
    }
   ],
   "source": [
    "import os\n",
    "pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
    "\n",
    "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)\n",
    "\n",
    "# Helper function to get the total number of classes for the detection task\n",
    "def get_num_classes(pbtxt_fname):\n",
    "    from object_detection.utils import label_map_util\n",
    "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
    "    categories = label_map_util.convert_label_map_to_categories(\n",
    "        label_map, max_num_classes=90, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "    return len(category_index.keys())\n",
    "  \n",
    "  \n",
    "import re\n",
    "\n",
    "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
    "with open(pipeline_fname) as f:\n",
    "    s = f.read()\n",
    "with open(pipeline_fname, 'w') as f:\n",
    "    \n",
    "    # fine_tune_checkpoint\n",
    "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
    "    \n",
    "    # tfrecord files train and test.\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
    "\n",
    "    # label_map_path\n",
    "    s = re.sub(\n",
    "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
    "\n",
    "    # Set training batch_size.\n",
    "    s = re.sub('batch_size: [0-9]+',\n",
    "               'batch_size: {}'.format(batch_size), s)\n",
    "\n",
    "    # Set training steps, num_steps\n",
    "    s = re.sub('num_steps: [0-9]+',\n",
    "               'num_steps: {}'.format(num_steps), s)\n",
    "    \n",
    "    # Set number of classes num_classes.\n",
    "    s = re.sub('num_classes: [0-9]+',\n",
    "               'num_classes: {}'.format(num_classes), s)\n",
    "    f.write(s)\n",
    "    \n",
    "# Viewing the pipeline\n",
    "!cat {pipeline_fname}\n",
    "\n",
    "model_dir = 'training/'\n",
    "# Optionally remove content in output model directory to fresh start.\n",
    "!rm -rf {model_dir}\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vreYFKmEZTEN"
   },
   "source": [
    "# Train and Eval Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VHMbsiyQM3m2",
    "outputId": "1b69b12f-ba91-4e11-ee37-6775b0f186ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
      "W0407 01:34:08.687649 139627316963200 model_lib.py:839] Forced number of epochs for all eval validations to be 1.\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 500\n",
      "I0407 01:34:08.687853 139627316963200 config_util.py:552] Maybe overwriting train_steps: 500\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0407 01:34:08.687962 139627316963200 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
      "I0407 01:34:08.688044 139627316963200 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
      "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
      "I0407 01:34:08.688147 139627316963200 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
      "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "W0407 01:34:08.688251 139627316963200 model_lib.py:855] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
      "I0407 01:34:08.688343 139627316963200 model_lib.py:892] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7efd11d0a710>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "I0407 01:34:08.689506 139627316963200 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7efd11d0a710>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7efd11c8a9e0>) includes params argument, but params are not passed to Estimator.\n",
      "W0407 01:34:08.689725 139627316963200 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7efd11c8a9e0>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "I0407 01:34:08.690124 139627316963200 estimator_training.py:186] Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "I0407 01:34:08.690289 139627316963200 training.py:612] Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "I0407 01:34:08.690487 139627316963200 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0407 01:34:08.701722 139627316963200 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/train.record']\n",
      "I0407 01:34:08.722216 139627316963200 dataset_builder.py:162] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/train.record']\n",
      "I0407 01:34:08.722920 139627316963200 dataset_builder.py:79] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0407 01:34:08.723048 139627316963200 dataset_builder.py:80] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0407 01:34:08.723141 139627316963200 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "W0407 01:34:08.727456 139627316963200 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0407 01:34:08.745654 139627316963200 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:113: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0407 01:34:21.122565 139627316963200 deprecation.py:323] From /content/models/research/object_detection/inputs.py:113: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:97: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0407 01:34:21.288254 139627316963200 deprecation.py:323] From /content/models/research/object_detection/inputs.py:97: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W0407 01:34:28.491612 139627316963200 api.py:332] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:288: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0407 01:34:31.931372 139627316963200 deprecation.py:323] From /content/models/research/object_detection/inputs.py:288: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0407 01:34:35.693410 139627316963200 estimator.py:1148] Calling model_fn.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "W0407 01:34:35.926523 139627316963200 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:34:38.400992 139627316963200 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:34:38.430145 139627316963200 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:34:38.457304 139627316963200 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:34:38.486118 139627316963200 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:34:38.513233 139627316963200 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:34:38.540309 139627316963200 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0407 01:34:43.015285 139627316963200 deprecation.py:506] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0407 01:34:48.934732 139627316963200 estimator.py:1150] Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "I0407 01:34:48.935973 139627316963200 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0407 01:34:52.142756 139627316963200 monitored_session.py:240] Graph was finalized.\n",
      "2022-04-07 01:34:52.157903: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
      "2022-04-07 01:34:52.158276: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c9106eee00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-04-07 01:34:52.158313: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-04-07 01:34:52.163586: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-04-07 01:34:52.455872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:34:52.456577: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c9106eea80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-04-07 01:34:52.456605: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2022-04-07 01:34:52.457767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:34:52.458333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2022-04-07 01:34:52.467940: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-07 01:34:52.629648: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-07 01:34:52.651253: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-07 01:34:52.667089: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-07 01:34:52.819950: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-07 01:34:52.834554: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-07 01:34:53.129779: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-07 01:34:53.130009: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:34:53.130776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:34:53.131365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2022-04-07 01:34:53.134094: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-07 01:34:53.135554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-04-07 01:34:53.135591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2022-04-07 01:34:53.135608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2022-04-07 01:34:53.136676: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:34:53.137363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:34:53.138003: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-04-07 01:34:53.138061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0407 01:34:58.923737 139627316963200 session_manager.py:500] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0407 01:34:59.238288 139627316963200 session_manager.py:502] Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.\n",
      "I0407 01:35:07.722288 139627316963200 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.\n",
      "2022-04-07 01:35:17.463983: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-07 01:35:20.012349: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "INFO:tensorflow:loss = 8.860786, step = 0\n",
      "I0407 01:35:23.333904 139627316963200 basic_session_run_hooks.py:262] loss = 8.860786, step = 0\n",
      "INFO:tensorflow:global_step/sec: 1.49301\n",
      "I0407 01:36:30.311719 139627316963200 basic_session_run_hooks.py:692] global_step/sec: 1.49301\n",
      "INFO:tensorflow:loss = 1.7120094, step = 100 (66.979 sec)\n",
      "I0407 01:36:30.312852 139627316963200 basic_session_run_hooks.py:260] loss = 1.7120094, step = 100 (66.979 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.57953\n",
      "I0407 01:37:33.621863 139627316963200 basic_session_run_hooks.py:692] global_step/sec: 1.57953\n",
      "INFO:tensorflow:loss = 0.8432032, step = 200 (63.310 sec)\n",
      "I0407 01:37:33.623116 139627316963200 basic_session_run_hooks.py:260] loss = 0.8432032, step = 200 (63.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.56062\n",
      "I0407 01:38:37.698859 139627316963200 basic_session_run_hooks.py:692] global_step/sec: 1.56062\n",
      "INFO:tensorflow:loss = 4.158203, step = 300 (64.077 sec)\n",
      "I0407 01:38:37.700102 139627316963200 basic_session_run_hooks.py:260] loss = 4.158203, step = 300 (64.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.53732\n",
      "I0407 01:39:42.747370 139627316963200 basic_session_run_hooks.py:692] global_step/sec: 1.53732\n",
      "INFO:tensorflow:loss = 0.98415124, step = 400 (65.049 sec)\n",
      "I0407 01:39:42.748696 139627316963200 basic_session_run_hooks.py:260] loss = 0.98415124, step = 400 (65.049 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 500 into training/model.ckpt.\n",
      "I0407 01:40:46.724076 139627316963200 basic_session_run_hooks.py:606] Saving checkpoints for 500 into training/model.ckpt.\n",
      "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test.record']\n",
      "I0407 01:40:48.083732 139627316963200 dataset_builder.py:162] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test.record']\n",
      "I0407 01:40:48.084451 139627316963200 dataset_builder.py:79] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0407 01:40:48.084587 139627316963200 dataset_builder.py:80] Number of filenames to read: 1\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0407 01:40:49.056337 139627316963200 estimator.py:1148] Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:40:50.985820 139627316963200 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:40:51.240144 139627316963200 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:40:51.268533 139627316963200 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:40:51.298771 139627316963200 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:40:51.328706 139627316963200 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:40:51.355765 139627316963200 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0407 01:40:52.004421 139627316963200 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "W0407 01:40:52.195207 139627316963200 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0407 01:40:52.677465 139627316963200 estimator.py:1150] Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-04-07T01:40:52Z\n",
      "I0407 01:40:52.692697 139627316963200 evaluation.py:255] Starting evaluation at 2022-04-07T01:40:52Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0407 01:40:53.076945 139627316963200 monitored_session.py:240] Graph was finalized.\n",
      "2022-04-07 01:40:53.078099: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:40:53.078530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2022-04-07 01:40:53.078647: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-07 01:40:53.078681: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-07 01:40:53.078708: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-07 01:40:53.078736: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-07 01:40:53.078764: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-07 01:40:53.078786: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-07 01:40:53.078810: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-07 01:40:53.078891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:40:53.079344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:40:53.079671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2022-04-07 01:40:53.079718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-04-07 01:40:53.079732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2022-04-07 01:40:53.079741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2022-04-07 01:40:53.079838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:40:53.080233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:40:53.080569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "INFO:tensorflow:Restoring parameters from training/model.ckpt-500\n",
      "I0407 01:40:53.081822 139627316963200 saver.py:1284] Restoring parameters from training/model.ckpt-500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0407 01:40:53.941120 139627316963200 session_manager.py:500] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0407 01:40:54.059397 139627316963200 session_manager.py:502] Done running local_init_op.\n",
      "INFO:tensorflow:Performing evaluation on 782 images.\n",
      "I0407 01:41:27.904680 139623473010432 coco_evaluation.py:293] Performing evaluation on 782 images.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I0407 01:41:27.907546 139623473010432 coco_tools.py:116] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.07s)\n",
      "I0407 01:41:27.976371 139623473010432 coco_tools.py:138] DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.06s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.47s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.851\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.946\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.910\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.851\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.894\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.905\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.907\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.907\n",
      "INFO:tensorflow:Finished evaluation at 2022-04-07-01:41:31\n",
      "I0407 01:41:31.685851 139627316963200 evaluation.py:275] Finished evaluation at 2022-04-07-01:41:31\n",
      "INFO:tensorflow:Saving dict for global step 500: DetectionBoxes_Precision/mAP = 0.85086507, DetectionBoxes_Precision/mAP (large) = 0.85086507, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9459998, DetectionBoxes_Precision/mAP@.75IOU = 0.90967405, DetectionBoxes_Recall/AR@1 = 0.89363676, DetectionBoxes_Recall/AR@10 = 0.9046816, DetectionBoxes_Recall/AR@100 = 0.90672845, DetectionBoxes_Recall/AR@100 (large) = 0.90672845, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 6.5799937, Loss/localization_loss = 2.467999, Loss/regularization_loss = 0.3074982, Loss/total_loss = 9.355527, global_step = 500, learning_rate = 0.004, loss = 9.355527\n",
      "I0407 01:41:31.686160 139627316963200 estimator.py:2049] Saving dict for global step 500: DetectionBoxes_Precision/mAP = 0.85086507, DetectionBoxes_Precision/mAP (large) = 0.85086507, DetectionBoxes_Precision/mAP (medium) = -1.0, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9459998, DetectionBoxes_Precision/mAP@.75IOU = 0.90967405, DetectionBoxes_Recall/AR@1 = 0.89363676, DetectionBoxes_Recall/AR@10 = 0.9046816, DetectionBoxes_Recall/AR@100 = 0.90672845, DetectionBoxes_Recall/AR@100 (large) = 0.90672845, DetectionBoxes_Recall/AR@100 (medium) = -1.0, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/classification_loss = 6.5799937, Loss/localization_loss = 2.467999, Loss/regularization_loss = 0.3074982, Loss/total_loss = 9.355527, global_step = 500, learning_rate = 0.004, loss = 9.355527\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 500: training/model.ckpt-500\n",
      "I0407 01:41:32.379540 139627316963200 estimator.py:2109] Saving 'checkpoint_path' summary for global step 500: training/model.ckpt-500\n",
      "INFO:tensorflow:Performing the final export in the end of training.\n",
      "I0407 01:41:32.380454 139627316963200 exporter.py:410] Performing the final export in the end of training.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0407 01:41:32.632150 139627316963200 estimator.py:1148] Calling model_fn.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:41:34.558435 139627316963200 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:41:34.588018 139627316963200 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:41:34.618939 139627316963200 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:41:34.649874 139627316963200 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:41:34.679732 139627316963200 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:41:34.711083 139627316963200 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0407 01:41:35.371228 139627316963200 estimator.py:1150] Done calling model_fn.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "W0407 01:41:35.371506 139627316963200 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "I0407 01:41:35.372068 139627316963200 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "I0407 01:41:35.372178 139627316963200 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
      "I0407 01:41:35.372257 139627316963200 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "I0407 01:41:35.372326 139627316963200 export_utils.py:170] Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "I0407 01:41:35.372392 139627316963200 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n",
      "2022-04-07 01:41:35.372911: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:41:35.373346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2022-04-07 01:41:35.373453: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-07 01:41:35.373486: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-07 01:41:35.373518: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-07 01:41:35.373545: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-07 01:41:35.373570: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-07 01:41:35.373591: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-07 01:41:35.373612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-07 01:41:35.373706: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:41:35.374125: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:41:35.374449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2022-04-07 01:41:35.374491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-04-07 01:41:35.374504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2022-04-07 01:41:35.374513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2022-04-07 01:41:35.374616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:41:35.375014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:41:35.375551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "INFO:tensorflow:Restoring parameters from training/model.ckpt-500\n",
      "I0407 01:41:35.377688 139627316963200 saver.py:1284] Restoring parameters from training/model.ckpt-500\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "I0407 01:41:35.781499 139627316963200 builder_impl.py:665] Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "I0407 01:41:35.781714 139627316963200 builder_impl.py:460] No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: training/export/Servo/temp-b'1649295692'/saved_model.pb\n",
      "I0407 01:41:36.442478 139627316963200 builder_impl.py:425] SavedModel written to: training/export/Servo/temp-b'1649295692'/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 0.9409437.\n",
      "I0407 01:41:36.785566 139627316963200 estimator.py:371] Loss for final step: 0.9409437.\n"
     ]
    }
   ],
   "source": [
    "!python /content/models/research/object_detection/model_main.py \\\n",
    "    --pipeline_config_path={pipeline_fname} \\\n",
    "    --model_dir={model_dir} \\\n",
    "    --alsologtostderr \\\n",
    "    --num_train_steps={num_steps} \\\n",
    "    --num_eval_steps=25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7MK9nMU-ZYml"
   },
   "source": [
    "# Train and Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3uzX80EoZiKo",
    "outputId": "65d709ea-29cf-4f54-d933-53d4dbefc1f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: /content/tensorflow-object-detection-faster-rcnn/data/test.record\n"
     ]
    }
   ],
   "source": [
    "# Create test data:\n",
    "!python /content/generate_tfrecord.py -x /content/tensorflow-object-detection-faster-rcnn/datauji -l /content/tensorflow-object-detection-faster-rcnn/data/label_map.pbtxt -o /content/tensorflow-object-detection-faster-rcnn/data/test.record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "daXShsR0Os53"
   },
   "source": [
    "## Using Last Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2LcnCGH0NFvY",
    "outputId": "52fbe11c-05d5-4660-fb4e-9c8f7a22c4ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/absl/app.py:258: main (from __main__) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use object_detection/model_main.py.\n",
      "W0407 01:41:44.398436 139708117907328 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/absl/app.py:258: main (from __main__) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use object_detection/model_main.py.\n",
      "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test.record']\n",
      "I0407 01:41:44.417296 139708117907328 dataset_builder.py:162] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test.record']\n",
      "I0407 01:41:44.418133 139708117907328 dataset_builder.py:79] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0407 01:41:44.418261 139708117907328 dataset_builder.py:80] Number of filenames to read: 1\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "W0407 01:41:44.421402 139708117907328 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0407 01:41:44.437595 139708117907328 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:48: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "W0407 01:41:47.688388 139708117907328 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:48: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/core/prefetcher.py:57: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0407 01:41:47.696200 139708117907328 deprecation.py:323] From /content/models/research/object_detection/core/prefetcher.py:57: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/core/prefetcher.py:57: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0407 01:41:47.697091 139708117907328 deprecation.py:323] From /content/models/research/object_detection/core/prefetcher.py:57: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "W0407 01:41:47.713335 139708117907328 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:41:49.780652 139708117907328 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:41:49.808777 139708117907328 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:41:49.836201 139708117907328 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:41:49.863745 139708117907328 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:41:49.891865 139708117907328 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:41:49.919274 139708117907328 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/core/post_processing.py:623: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0407 01:41:50.052422 139708117907328 deprecation.py:323] From /content/models/research/object_detection/core/post_processing.py:623: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0407 01:41:50.616509 139708117907328 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Starting evaluation at 2022-04-07-01:41:51\n",
      "I0407 01:41:51.044887 139708117907328 eval_util.py:506] Starting evaluation at 2022-04-07-01:41:51\n",
      "2022-04-07 01:41:51.047570: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-04-07 01:41:51.083386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:41:51.084073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2022-04-07 01:41:51.084475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-07 01:41:51.086349: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-07 01:41:51.094423: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-07 01:41:51.094762: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-07 01:41:51.103448: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-07 01:41:51.104388: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-07 01:41:51.110925: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-07 01:41:51.111076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:41:51.111664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:41:51.112203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2022-04-07 01:41:51.122346: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
      "2022-04-07 01:41:51.122534: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5570119e2000 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-04-07 01:41:51.122563: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-04-07 01:41:51.321755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:41:51.322558: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5570119e3340 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-04-07 01:41:51.322594: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2022-04-07 01:41:51.322781: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:41:51.323373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2022-04-07 01:41:51.323459: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-07 01:41:51.323493: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-07 01:41:51.323518: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-07 01:41:51.323543: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-07 01:41:51.323565: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-07 01:41:51.323586: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-07 01:41:51.323608: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-07 01:41:51.323691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:41:51.324317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:41:51.324861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2022-04-07 01:41:51.324934: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-07 01:41:51.326221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-04-07 01:41:51.326249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2022-04-07 01:41:51.326259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2022-04-07 01:41:51.326379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:41:51.326997: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:41:51.327558: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-04-07 01:41:51.327597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "INFO:tensorflow:Restoring parameters from /content/models/research/training/model.ckpt-500\n",
      "I0407 01:41:52.621901 139708117907328 saver.py:1284] Restoring parameters from /content/models/research/training/model.ckpt-500\n",
      "2022-04-07 01:41:59.756294: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-07 01:42:01.326468: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "INFO:tensorflow:Creating detection visualizations.\n",
      "I0407 01:42:02.729368 139708117907328 eval_util.py:178] Creating detection visualizations.\n",
      "INFO:tensorflow:Detection visualizations written to summary with tag image-0.\n",
      "I0407 01:42:04.618428 139708117907328 eval_util.py:243] Detection visualizations written to summary with tag image-0.\n",
      "INFO:tensorflow:Creating detection visualizations.\n",
      "I0407 01:42:05.885533 139708117907328 eval_util.py:178] Creating detection visualizations.\n",
      "INFO:tensorflow:Detection visualizations written to summary with tag image-1.\n",
      "I0407 01:42:07.046082 139708117907328 eval_util.py:243] Detection visualizations written to summary with tag image-1.\n",
      "INFO:tensorflow:Creating detection visualizations.\n",
      "I0407 01:42:07.670108 139708117907328 eval_util.py:178] Creating detection visualizations.\n",
      "INFO:tensorflow:Detection visualizations written to summary with tag image-2.\n",
      "I0407 01:42:08.073091 139708117907328 eval_util.py:243] Detection visualizations written to summary with tag image-2.\n",
      "INFO:tensorflow:Creating detection visualizations.\n",
      "I0407 01:42:08.661486 139708117907328 eval_util.py:178] Creating detection visualizations.\n",
      "INFO:tensorflow:Detection visualizations written to summary with tag image-3.\n",
      "I0407 01:42:09.547185 139708117907328 eval_util.py:243] Detection visualizations written to summary with tag image-3.\n",
      "INFO:tensorflow:Creating detection visualizations.\n",
      "I0407 01:42:10.248792 139708117907328 eval_util.py:178] Creating detection visualizations.\n",
      "INFO:tensorflow:Detection visualizations written to summary with tag image-4.\n",
      "I0407 01:42:11.074072 139708117907328 eval_util.py:243] Detection visualizations written to summary with tag image-4.\n",
      "INFO:tensorflow:Creating detection visualizations.\n",
      "I0407 01:42:11.598444 139708117907328 eval_util.py:178] Creating detection visualizations.\n",
      "INFO:tensorflow:Detection visualizations written to summary with tag image-5.\n",
      "I0407 01:42:13.131927 139708117907328 eval_util.py:243] Detection visualizations written to summary with tag image-5.\n",
      "INFO:tensorflow:Creating detection visualizations.\n",
      "I0407 01:42:13.992568 139708117907328 eval_util.py:178] Creating detection visualizations.\n",
      "INFO:tensorflow:Detection visualizations written to summary with tag image-6.\n",
      "I0407 01:42:14.835094 139708117907328 eval_util.py:243] Detection visualizations written to summary with tag image-6.\n",
      "INFO:tensorflow:Creating detection visualizations.\n",
      "I0407 01:42:15.760830 139708117907328 eval_util.py:178] Creating detection visualizations.\n",
      "INFO:tensorflow:Detection visualizations written to summary with tag image-7.\n",
      "I0407 01:42:17.393175 139708117907328 eval_util.py:243] Detection visualizations written to summary with tag image-7.\n",
      "INFO:tensorflow:Creating detection visualizations.\n",
      "I0407 01:42:18.149387 139708117907328 eval_util.py:178] Creating detection visualizations.\n",
      "INFO:tensorflow:Detection visualizations written to summary with tag image-8.\n",
      "I0407 01:42:19.175263 139708117907328 eval_util.py:243] Detection visualizations written to summary with tag image-8.\n",
      "INFO:tensorflow:Creating detection visualizations.\n",
      "I0407 01:42:20.723551 139708117907328 eval_util.py:178] Creating detection visualizations.\n",
      "INFO:tensorflow:Detection visualizations written to summary with tag image-9.\n",
      "I0407 01:42:21.922611 139708117907328 eval_util.py:243] Detection visualizations written to summary with tag image-9.\n",
      "INFO:tensorflow:Running eval ops batch 100/100\n",
      "I0407 01:42:50.709545 139708117907328 eval_util.py:342] Running eval ops batch 100/100\n",
      "INFO:tensorflow:Running eval batches done.\n",
      "I0407 01:42:50.854161 139708117907328 eval_util.py:376] Running eval batches done.\n",
      "INFO:tensorflow:# success: 100\n",
      "I0407 01:42:50.854354 139708117907328 eval_util.py:381] # success: 100\n",
      "INFO:tensorflow:# skipped: 0\n",
      "I0407 01:42:50.854445 139708117907328 eval_util.py:382] # skipped: 0\n",
      "INFO:tensorflow:Performing evaluation on 100 images.\n",
      "I0407 01:42:50.854522 139708117907328 coco_evaluation.py:293] Performing evaluation on 100 images.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I0407 01:42:50.854849 139708117907328 coco_tools.py:116] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "I0407 01:42:50.859752 139708117907328 coco_tools.py:138] DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.29s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.06s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.683\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.790\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.710\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.683\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.768\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.809\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.832\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.832\n",
      "INFO:tensorflow:Writing metrics to tf summary.\n",
      "I0407 01:42:51.716090 139708117907328 eval_util.py:90] Writing metrics to tf summary.\n",
      "INFO:tensorflow:DetectionBoxes_Precision/mAP: 0.683286\n",
      "I0407 01:42:51.716484 139708117907328 eval_util.py:97] DetectionBoxes_Precision/mAP: 0.683286\n",
      "INFO:tensorflow:DetectionBoxes_Precision/mAP (large): 0.683286\n",
      "I0407 01:42:51.716944 139708117907328 eval_util.py:97] DetectionBoxes_Precision/mAP (large): 0.683286\n",
      "INFO:tensorflow:DetectionBoxes_Precision/mAP (medium): -1.000000\n",
      "I0407 01:42:51.717252 139708117907328 eval_util.py:97] DetectionBoxes_Precision/mAP (medium): -1.000000\n",
      "INFO:tensorflow:DetectionBoxes_Precision/mAP (small): -1.000000\n",
      "I0407 01:42:51.717493 139708117907328 eval_util.py:97] DetectionBoxes_Precision/mAP (small): -1.000000\n",
      "INFO:tensorflow:DetectionBoxes_Precision/mAP@.50IOU: 0.790239\n",
      "I0407 01:42:51.717729 139708117907328 eval_util.py:97] DetectionBoxes_Precision/mAP@.50IOU: 0.790239\n",
      "INFO:tensorflow:DetectionBoxes_Precision/mAP@.75IOU: 0.710185\n",
      "I0407 01:42:51.717972 139708117907328 eval_util.py:97] DetectionBoxes_Precision/mAP@.75IOU: 0.710185\n",
      "INFO:tensorflow:DetectionBoxes_Recall/AR@1: 0.768002\n",
      "I0407 01:42:51.718218 139708117907328 eval_util.py:97] DetectionBoxes_Recall/AR@1: 0.768002\n",
      "INFO:tensorflow:DetectionBoxes_Recall/AR@10: 0.809441\n",
      "I0407 01:42:51.718421 139708117907328 eval_util.py:97] DetectionBoxes_Recall/AR@10: 0.809441\n",
      "INFO:tensorflow:DetectionBoxes_Recall/AR@100: 0.831998\n",
      "I0407 01:42:51.718622 139708117907328 eval_util.py:97] DetectionBoxes_Recall/AR@100: 0.831998\n",
      "INFO:tensorflow:DetectionBoxes_Recall/AR@100 (large): 0.831998\n",
      "I0407 01:42:51.718813 139708117907328 eval_util.py:97] DetectionBoxes_Recall/AR@100 (large): 0.831998\n",
      "INFO:tensorflow:DetectionBoxes_Recall/AR@100 (medium): -1.000000\n",
      "I0407 01:42:51.719012 139708117907328 eval_util.py:97] DetectionBoxes_Recall/AR@100 (medium): -1.000000\n",
      "INFO:tensorflow:DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
      "I0407 01:42:51.719228 139708117907328 eval_util.py:97] DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
      "INFO:tensorflow:Losses/Loss/classification_loss: 6.592207\n",
      "I0407 01:42:51.719420 139708117907328 eval_util.py:97] Losses/Loss/classification_loss: 6.592207\n",
      "INFO:tensorflow:Losses/Loss/localization_loss: 2.564499\n",
      "I0407 01:42:51.719618 139708117907328 eval_util.py:97] Losses/Loss/localization_loss: 2.564499\n",
      "INFO:tensorflow:Metrics written to tf summary.\n",
      "I0407 01:42:51.719779 139708117907328 eval_util.py:98] Metrics written to tf summary.\n",
      "INFO:tensorflow:Starting evaluation at 2022-04-07-01:46:51\n",
      "I0407 01:46:51.111477 139708117907328 eval_util.py:506] Starting evaluation at 2022-04-07-01:46:51\n",
      "INFO:tensorflow:Found already evaluated checkpoint. Will try again in 300 seconds\n",
      "I0407 01:46:51.113754 139708117907328 eval_util.py:513] Found already evaluated checkpoint. Will try again in 300 seconds\n",
      "INFO:tensorflow:Finished evaluation!\n",
      "I0407 01:46:51.113963 139708117907328 eval_util.py:539] Finished evaluation!\n"
     ]
    }
   ],
   "source": [
    "!python /content/models/research/object_detection/legacy/eval.py --pipeline_config_path={pipeline_fname} --eval_dir=/content/models/research/training/eval_1 --checkpoint_dir=/content/models/research/training --alsologtostderr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JGuGHgE8Ov83"
   },
   "source": [
    "## Using Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KHmzD7pxJPhT",
    "outputId": "251b325e-7b3a-49f8-b4c2-29774bbc758a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/absl/app.py:258: main (from __main__) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use object_detection/model_main.py.\n",
      "W0407 01:53:56.860350 140686801659776 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/absl/app.py:258: main (from __main__) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use object_detection/model_main.py.\n",
      "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test.record']\n",
      "I0407 01:53:56.879154 140686801659776 dataset_builder.py:162] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/test.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test.record']\n",
      "I0407 01:53:56.879946 140686801659776 dataset_builder.py:79] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/test.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0407 01:53:56.880086 140686801659776 dataset_builder.py:80] Number of filenames to read: 1\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "W0407 01:53:56.883417 140686801659776 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0407 01:53:56.899941 140686801659776 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:48: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "W0407 01:54:00.241641 140686801659776 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:48: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/core/prefetcher.py:57: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0407 01:54:00.250235 140686801659776 deprecation.py:323] From /content/models/research/object_detection/core/prefetcher.py:57: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/core/prefetcher.py:57: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0407 01:54:00.251231 140686801659776 deprecation.py:323] From /content/models/research/object_detection/core/prefetcher.py:57: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "W0407 01:54:00.268933 140686801659776 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:54:02.372262 140686801659776 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:54:02.401503 140686801659776 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:54:02.429473 140686801659776 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:54:02.459067 140686801659776 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:54:02.487823 140686801659776 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:54:02.516178 140686801659776 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/core/post_processing.py:623: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0407 01:54:02.655869 140686801659776 deprecation.py:323] From /content/models/research/object_detection/core/post_processing.py:623: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0407 01:54:03.228990 140686801659776 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Starting evaluation at 2022-04-07-01:54:03\n",
      "I0407 01:54:03.660999 140686801659776 eval_util.py:506] Starting evaluation at 2022-04-07-01:54:03\n",
      "2022-04-07 01:54:03.663523: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-04-07 01:54:03.691948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:54:03.692548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2022-04-07 01:54:03.692876: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-07 01:54:03.694420: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-07 01:54:03.695676: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-07 01:54:03.695980: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-07 01:54:03.697799: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-07 01:54:03.698795: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-07 01:54:03.702577: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-07 01:54:03.702701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:54:03.703291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:54:03.703802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2022-04-07 01:54:03.708769: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
      "2022-04-07 01:54:03.708953: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fdf76799c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-04-07 01:54:03.708983: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-04-07 01:54:03.901456: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:54:03.902218: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fdf7679640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-04-07 01:54:03.902252: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2022-04-07 01:54:03.902445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:54:03.902979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2022-04-07 01:54:03.903064: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-07 01:54:03.903100: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-07 01:54:03.903121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-07 01:54:03.903142: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-07 01:54:03.903161: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-07 01:54:03.903180: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-07 01:54:03.903201: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-07 01:54:03.903280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:54:03.903829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:54:03.904353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2022-04-07 01:54:03.904432: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-07 01:54:03.905634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-04-07 01:54:03.905663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2022-04-07 01:54:03.905675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2022-04-07 01:54:03.905813: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:54:03.906430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:54:03.906939: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-04-07 01:54:03.906983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "INFO:tensorflow:Restoring parameters from /content/models/research/fine_tuned_model/model.ckpt\n",
      "I0407 01:54:05.238348 140686801659776 saver.py:1284] Restoring parameters from /content/models/research/fine_tuned_model/model.ckpt\n",
      "2022-04-07 01:54:12.227861: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-07 01:54:15.212844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "INFO:tensorflow:Creating detection visualizations.\n",
      "I0407 01:54:18.392503 140686801659776 eval_util.py:178] Creating detection visualizations.\n",
      "INFO:tensorflow:Detection visualizations written to summary with tag image-0.\n",
      "I0407 01:54:21.504207 140686801659776 eval_util.py:243] Detection visualizations written to summary with tag image-0.\n",
      "INFO:tensorflow:Creating detection visualizations.\n",
      "I0407 01:54:22.290321 140686801659776 eval_util.py:178] Creating detection visualizations.\n",
      "INFO:tensorflow:Detection visualizations written to summary with tag image-1.\n",
      "I0407 01:54:24.321826 140686801659776 eval_util.py:243] Detection visualizations written to summary with tag image-1.\n",
      "INFO:tensorflow:Creating detection visualizations.\n",
      "I0407 01:54:25.512591 140686801659776 eval_util.py:178] Creating detection visualizations.\n",
      "INFO:tensorflow:Detection visualizations written to summary with tag image-2.\n",
      "I0407 01:54:26.302702 140686801659776 eval_util.py:243] Detection visualizations written to summary with tag image-2.\n",
      "INFO:tensorflow:Creating detection visualizations.\n",
      "I0407 01:54:27.723476 140686801659776 eval_util.py:178] Creating detection visualizations.\n",
      "INFO:tensorflow:Detection visualizations written to summary with tag image-3.\n",
      "I0407 01:54:29.273201 140686801659776 eval_util.py:243] Detection visualizations written to summary with tag image-3.\n",
      "INFO:tensorflow:Creating detection visualizations.\n",
      "I0407 01:54:32.141389 140686801659776 eval_util.py:178] Creating detection visualizations.\n",
      "INFO:tensorflow:Detection visualizations written to summary with tag image-4.\n",
      "I0407 01:54:33.294468 140686801659776 eval_util.py:243] Detection visualizations written to summary with tag image-4.\n",
      "INFO:tensorflow:Creating detection visualizations.\n",
      "I0407 01:54:33.933288 140686801659776 eval_util.py:178] Creating detection visualizations.\n",
      "INFO:tensorflow:Detection visualizations written to summary with tag image-5.\n",
      "I0407 01:54:35.722835 140686801659776 eval_util.py:243] Detection visualizations written to summary with tag image-5.\n",
      "INFO:tensorflow:Creating detection visualizations.\n",
      "I0407 01:54:36.535086 140686801659776 eval_util.py:178] Creating detection visualizations.\n",
      "INFO:tensorflow:Detection visualizations written to summary with tag image-6.\n",
      "I0407 01:54:37.345695 140686801659776 eval_util.py:243] Detection visualizations written to summary with tag image-6.\n",
      "INFO:tensorflow:Creating detection visualizations.\n",
      "I0407 01:54:38.140366 140686801659776 eval_util.py:178] Creating detection visualizations.\n",
      "INFO:tensorflow:Detection visualizations written to summary with tag image-7.\n",
      "I0407 01:54:39.966453 140686801659776 eval_util.py:243] Detection visualizations written to summary with tag image-7.\n",
      "INFO:tensorflow:Creating detection visualizations.\n",
      "I0407 01:54:40.524733 140686801659776 eval_util.py:178] Creating detection visualizations.\n",
      "INFO:tensorflow:Detection visualizations written to summary with tag image-8.\n",
      "I0407 01:54:41.499595 140686801659776 eval_util.py:243] Detection visualizations written to summary with tag image-8.\n",
      "INFO:tensorflow:Creating detection visualizations.\n",
      "I0407 01:54:41.906775 140686801659776 eval_util.py:178] Creating detection visualizations.\n",
      "INFO:tensorflow:Detection visualizations written to summary with tag image-9.\n",
      "I0407 01:54:43.116226 140686801659776 eval_util.py:243] Detection visualizations written to summary with tag image-9.\n",
      "INFO:tensorflow:Running eval ops batch 100/100\n",
      "I0407 01:55:13.461681 140686801659776 eval_util.py:342] Running eval ops batch 100/100\n",
      "INFO:tensorflow:Running eval batches done.\n",
      "I0407 01:55:13.607184 140686801659776 eval_util.py:376] Running eval batches done.\n",
      "INFO:tensorflow:# success: 100\n",
      "I0407 01:55:13.607427 140686801659776 eval_util.py:381] # success: 100\n",
      "INFO:tensorflow:# skipped: 0\n",
      "I0407 01:55:13.607536 140686801659776 eval_util.py:382] # skipped: 0\n",
      "INFO:tensorflow:Performing evaluation on 100 images.\n",
      "I0407 01:55:13.607628 140686801659776 coco_evaluation.py:293] Performing evaluation on 100 images.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I0407 01:55:13.608059 140686801659776 coco_tools.py:116] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.01s)\n",
      "I0407 01:55:13.615958 140686801659776 coco_tools.py:138] DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.30s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.07s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.683\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.790\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.710\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.683\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.768\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.809\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.832\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.832\n",
      "INFO:tensorflow:Writing metrics to tf summary.\n",
      "I0407 01:55:14.462343 140686801659776 eval_util.py:90] Writing metrics to tf summary.\n",
      "INFO:tensorflow:DetectionBoxes_Precision/mAP: 0.683286\n",
      "I0407 01:55:14.462727 140686801659776 eval_util.py:97] DetectionBoxes_Precision/mAP: 0.683286\n",
      "INFO:tensorflow:DetectionBoxes_Precision/mAP (large): 0.683286\n",
      "I0407 01:55:14.465446 140686801659776 eval_util.py:97] DetectionBoxes_Precision/mAP (large): 0.683286\n",
      "INFO:tensorflow:DetectionBoxes_Precision/mAP (medium): -1.000000\n",
      "I0407 01:55:14.465748 140686801659776 eval_util.py:97] DetectionBoxes_Precision/mAP (medium): -1.000000\n",
      "INFO:tensorflow:DetectionBoxes_Precision/mAP (small): -1.000000\n",
      "I0407 01:55:14.466000 140686801659776 eval_util.py:97] DetectionBoxes_Precision/mAP (small): -1.000000\n",
      "INFO:tensorflow:DetectionBoxes_Precision/mAP@.50IOU: 0.790239\n",
      "I0407 01:55:14.466276 140686801659776 eval_util.py:97] DetectionBoxes_Precision/mAP@.50IOU: 0.790239\n",
      "INFO:tensorflow:DetectionBoxes_Precision/mAP@.75IOU: 0.710185\n",
      "I0407 01:55:14.466544 140686801659776 eval_util.py:97] DetectionBoxes_Precision/mAP@.75IOU: 0.710185\n",
      "INFO:tensorflow:DetectionBoxes_Recall/AR@1: 0.768002\n",
      "I0407 01:55:14.466792 140686801659776 eval_util.py:97] DetectionBoxes_Recall/AR@1: 0.768002\n",
      "INFO:tensorflow:DetectionBoxes_Recall/AR@10: 0.809441\n",
      "I0407 01:55:14.467025 140686801659776 eval_util.py:97] DetectionBoxes_Recall/AR@10: 0.809441\n",
      "INFO:tensorflow:DetectionBoxes_Recall/AR@100: 0.831998\n",
      "I0407 01:55:14.467279 140686801659776 eval_util.py:97] DetectionBoxes_Recall/AR@100: 0.831998\n",
      "INFO:tensorflow:DetectionBoxes_Recall/AR@100 (large): 0.831998\n",
      "I0407 01:55:14.467500 140686801659776 eval_util.py:97] DetectionBoxes_Recall/AR@100 (large): 0.831998\n",
      "INFO:tensorflow:DetectionBoxes_Recall/AR@100 (medium): -1.000000\n",
      "I0407 01:55:14.467710 140686801659776 eval_util.py:97] DetectionBoxes_Recall/AR@100 (medium): -1.000000\n",
      "INFO:tensorflow:DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
      "I0407 01:55:14.467906 140686801659776 eval_util.py:97] DetectionBoxes_Recall/AR@100 (small): -1.000000\n",
      "INFO:tensorflow:Losses/Loss/classification_loss: 6.592207\n",
      "I0407 01:55:14.468134 140686801659776 eval_util.py:97] Losses/Loss/classification_loss: 6.592207\n",
      "INFO:tensorflow:Losses/Loss/localization_loss: 2.564499\n",
      "I0407 01:55:14.468259 140686801659776 eval_util.py:97] Losses/Loss/localization_loss: 2.564499\n",
      "INFO:tensorflow:Metrics written to tf summary.\n",
      "I0407 01:55:14.468348 140686801659776 eval_util.py:98] Metrics written to tf summary.\n",
      "INFO:tensorflow:Starting evaluation at 2022-04-07-01:59:03\n",
      "I0407 01:59:03.744700 140686801659776 eval_util.py:506] Starting evaluation at 2022-04-07-01:59:03\n",
      "INFO:tensorflow:Found already evaluated checkpoint. Will try again in 300 seconds\n",
      "I0407 01:59:03.746774 140686801659776 eval_util.py:513] Found already evaluated checkpoint. Will try again in 300 seconds\n",
      "INFO:tensorflow:Finished evaluation!\n",
      "I0407 01:59:03.746949 140686801659776 eval_util.py:539] Finished evaluation!\n"
     ]
    }
   ],
   "source": [
    "!python /content/models/research/object_detection/legacy/eval.py --pipeline_config_path=/content/models/research/fine_tuned_model/pipeline.config --eval_dir=/content/models/research/fine_tuned_model/eval_0 --checkpoint_dir=/content/models/research/fine_tuned_model --alsologtostderr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fR1JxrPAlkg-"
   },
   "source": [
    "# Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QpxkZ9iklj0G",
    "outputId": "0c9fee10-cab3-42ec-8138-d632a2a5beee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training/model.ckpt-500\n",
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "W0407 01:53:36.634775 140392554559360 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:53:38.618995 140392554559360 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:53:38.655335 140392554559360 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:53:38.691787 140392554559360 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:53:38.728274 140392554559360 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:53:38.765041 140392554559360 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0407 01:53:38.799457 140392554559360 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/core/post_processing.py:623: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0407 01:53:39.157351 140392554559360 deprecation.py:323] From /content/models/research/object_detection/core/post_processing.py:623: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "W0407 01:53:39.506388 140392554559360 deprecation.py:323] From /content/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
      "Instructions for updating:\n",
      "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
      "W0407 01:53:39.509677 140392554559360 deprecation.py:323] From /content/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
      "Instructions for updating:\n",
      "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "W0407 01:53:39.510246 140392554559360 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "135 ops no flops stats due to incomplete shapes.\n",
      "Parsing Inputs...\n",
      "Incomplete shape.\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              0\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   name\n",
      "-account_type_regexes       _trainable_variables\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          .*BatchNorm.*\n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     params\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "Incomplete shape.\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "param: Number of parameters (in the Variable).\n",
      "\n",
      "Profile:\n",
      "node name | # parameters\n",
      "_TFProfRoot (--/4.59m params)\n",
      "  BoxPredictor_0 (--/12.12k params)\n",
      "    BoxPredictor_0/BoxEncodingPredictor (--/6.92k params)\n",
      "      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n",
      "      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x576x12, 6.91k/6.91k params)\n",
      "    BoxPredictor_0/ClassPredictor (--/5.19k params)\n",
      "      BoxPredictor_0/ClassPredictor/biases (9, 9/9 params)\n",
      "      BoxPredictor_0/ClassPredictor/weights (1x1x576x9, 5.18k/5.18k params)\n",
      "  BoxPredictor_1 (--/53.80k params)\n",
      "    BoxPredictor_1/BoxEncodingPredictor (--/30.74k params)\n",
      "      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n",
      "      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x1280x24, 30.72k/30.72k params)\n",
      "    BoxPredictor_1/ClassPredictor (--/23.06k params)\n",
      "      BoxPredictor_1/ClassPredictor/biases (18, 18/18 params)\n",
      "      BoxPredictor_1/ClassPredictor/weights (1x1x1280x18, 23.04k/23.04k params)\n",
      "  BoxPredictor_2 (--/21.55k params)\n",
      "    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n",
      "      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n",
      "      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
      "    BoxPredictor_2/ClassPredictor (--/9.23k params)\n",
      "      BoxPredictor_2/ClassPredictor/biases (18, 18/18 params)\n",
      "      BoxPredictor_2/ClassPredictor/weights (1x1x512x18, 9.22k/9.22k params)\n",
      "  BoxPredictor_3 (--/10.79k params)\n",
      "    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n",
      "      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n",
      "      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
      "    BoxPredictor_3/ClassPredictor (--/4.63k params)\n",
      "      BoxPredictor_3/ClassPredictor/biases (18, 18/18 params)\n",
      "      BoxPredictor_3/ClassPredictor/weights (1x1x256x18, 4.61k/4.61k params)\n",
      "  BoxPredictor_4 (--/10.79k params)\n",
      "    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n",
      "      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n",
      "      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
      "    BoxPredictor_4/ClassPredictor (--/4.63k params)\n",
      "      BoxPredictor_4/ClassPredictor/biases (18, 18/18 params)\n",
      "      BoxPredictor_4/ClassPredictor/weights (1x1x256x18, 4.61k/4.61k params)\n",
      "  BoxPredictor_5 (--/5.42k params)\n",
      "    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n",
      "      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n",
      "      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n",
      "    BoxPredictor_5/ClassPredictor (--/2.32k params)\n",
      "      BoxPredictor_5/ClassPredictor/biases (18, 18/18 params)\n",
      "      BoxPredictor_5/ClassPredictor/weights (1x1x128x18, 2.30k/2.30k params)\n",
      "  FeatureExtractor (--/4.48m params)\n",
      "    FeatureExtractor/MobilenetV2 (--/4.48m params)\n",
      "      FeatureExtractor/MobilenetV2/Conv (--/864 params)\n",
      "        FeatureExtractor/MobilenetV2/Conv/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/Conv/weights (3x3x3x32, 864/864 params)\n",
      "      FeatureExtractor/MobilenetV2/Conv_1 (--/409.60k params)\n",
      "        FeatureExtractor/MobilenetV2/Conv_1/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/Conv_1/weights (1x1x320x1280, 409.60k/409.60k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv (--/800 params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv/depthwise (--/288 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv/project (--/512 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv/project/weights (1x1x32x16, 512/512 params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_1 (--/4.70k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise (--/864 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights (3x3x96x1, 864/864 params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_1/expand (--/1.54k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/weights (1x1x16x96, 1.54k/1.54k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_1/project (--/2.30k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_1/project/weights (1x1x96x24, 2.30k/2.30k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_10 (--/64.90k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise (--/3.46k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_10/expand (--/24.58k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_10/project (--/36.86k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_10/project/weights (1x1x384x96, 36.86k/36.86k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_11 (--/115.78k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise (--/5.18k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_11/expand (--/55.30k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_11/project (--/55.30k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_11/project/weights (1x1x576x96, 55.30k/55.30k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_12 (--/115.78k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise (--/5.18k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_12/expand (--/55.30k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_12/project (--/55.30k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_12/project/weights (1x1x576x96, 55.30k/55.30k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_13 (--/152.64k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise (--/5.18k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_13/expand (--/55.30k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_13/project (--/92.16k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_13/project/weights (1x1x576x160, 92.16k/92.16k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_14 (--/315.84k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise (--/8.64k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_14/expand (--/153.60k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_14/project (--/153.60k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_14/project/weights (1x1x960x160, 153.60k/153.60k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_15 (--/315.84k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise (--/8.64k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_15/expand (--/153.60k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_15/project (--/153.60k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_15/project/weights (1x1x960x160, 153.60k/153.60k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_16 (--/469.44k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise (--/8.64k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_16/expand (--/153.60k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_16/project (--/307.20k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_16/project/weights (1x1x960x320, 307.20k/307.20k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_2 (--/8.21k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise (--/1.30k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_2/expand (--/3.46k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/weights (1x1x24x144, 3.46k/3.46k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_2/project (--/3.46k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_2/project/weights (1x1x144x24, 3.46k/3.46k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_3 (--/9.36k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise (--/1.30k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_3/expand (--/3.46k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/weights (1x1x24x144, 3.46k/3.46k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_3/project (--/4.61k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_3/project/weights (1x1x144x32, 4.61k/4.61k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_4 (--/14.02k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise (--/1.73k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_4/expand (--/6.14k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_4/project (--/6.14k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_4/project/weights (1x1x192x32, 6.14k/6.14k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_5 (--/14.02k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise (--/1.73k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_5/expand (--/6.14k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_5/project (--/6.14k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_5/project/weights (1x1x192x32, 6.14k/6.14k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_6 (--/20.16k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise (--/1.73k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_6/expand (--/6.14k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_6/project (--/12.29k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_6/project/weights (1x1x192x64, 12.29k/12.29k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_7 (--/52.61k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise (--/3.46k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_7/expand (--/24.58k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_7/project (--/24.58k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_7/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_8 (--/52.61k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise (--/3.46k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_8/expand (--/24.58k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_8/project (--/24.58k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_8/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
      "      FeatureExtractor/MobilenetV2/expanded_conv_9 (--/52.61k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise (--/3.46k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_9/expand (--/24.58k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
      "        FeatureExtractor/MobilenetV2/expanded_conv_9/project (--/24.58k params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm (--/0 params)\n",
      "          FeatureExtractor/MobilenetV2/expanded_conv_9/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256 (--/327.68k params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights (1x1x1280x256, 327.68k/327.68k params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128 (--/65.54k params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128 (--/32.77k params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64 (--/16.38k params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512 (--/1.18m params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights (3x3x256x512, 1.18m/1.18m params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256 (--/294.91k params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256 (--/294.91k params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n",
      "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128 (--/73.73k params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights (3x3x64x128, 73.73k/73.73k params)\n",
      "\n",
      "======================End of Report==========================\n",
      "135 ops no flops stats due to incomplete shapes.\n",
      "Parsing Inputs...\n",
      "Incomplete shape.\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "Incomplete shape.\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/36.16k flops)\n",
      "  MultipleGridAnchorGenerator/mul_19 (6.14k/6.14k flops)\n",
      "  MultipleGridAnchorGenerator/sub (6.14k/6.14k flops)\n",
      "  MultipleGridAnchorGenerator/mul_20 (6.14k/6.14k flops)\n",
      "  MultipleGridAnchorGenerator/mul_28 (3.07k/3.07k flops)\n",
      "  MultipleGridAnchorGenerator/mul_27 (3.07k/3.07k flops)\n",
      "  MultipleGridAnchorGenerator/mul_21 (3.07k/3.07k flops)\n",
      "  MultipleGridAnchorGenerator/sub_1 (3.07k/3.07k flops)\n",
      "  MultipleGridAnchorGenerator/mul_29 (1.54k/1.54k flops)\n",
      "  MultipleGridAnchorGenerator/mul_35 (768/768 flops)\n",
      "  MultipleGridAnchorGenerator/sub_2 (768/768 flops)\n",
      "  MultipleGridAnchorGenerator/mul_36 (768/768 flops)\n",
      "  MultipleGridAnchorGenerator/mul_37 (384/384 flops)\n",
      "  MultipleGridAnchorGenerator/mul_44 (192/192 flops)\n",
      "  MultipleGridAnchorGenerator/mul_43 (192/192 flops)\n",
      "  MultipleGridAnchorGenerator/sub_3 (192/192 flops)\n",
      "  MultipleGridAnchorGenerator/mul_45 (96/96 flops)\n",
      "  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n",
      "  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n",
      "  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n",
      "  MultipleGridAnchorGenerator/mul_18 (32/32 flops)\n",
      "  MultipleGridAnchorGenerator/mul_17 (32/32 flops)\n",
      "  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n",
      "  MultipleGridAnchorGenerator/mul_25 (16/16 flops)\n",
      "  MultipleGridAnchorGenerator/mul_26 (16/16 flops)\n",
      "  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n",
      "  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n",
      "  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n",
      "  MultipleGridAnchorGenerator/mul_33 (8/8 flops)\n",
      "  MultipleGridAnchorGenerator/mul_34 (8/8 flops)\n",
      "  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_42 (4/4 flops)\n",
      "  MultipleGridAnchorGenerator/mul_41 (4/4 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_3 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
      "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
      "  Preprocessor/map/while/Less (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "2022-04-07 01:53:41.285403: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-04-07 01:53:41.314892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:53:41.315505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2022-04-07 01:53:41.315816: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-07 01:53:41.317410: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-07 01:53:41.318604: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-07 01:53:41.318927: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-07 01:53:41.320714: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-07 01:53:41.331132: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-07 01:53:41.337526: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-07 01:53:41.337645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:53:41.338253: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:53:41.338761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2022-04-07 01:53:41.343730: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
      "2022-04-07 01:53:41.343895: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e57e132140 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-04-07 01:53:41.343922: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-04-07 01:53:41.544566: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:53:41.545384: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e57e132300 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-04-07 01:53:41.545420: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2022-04-07 01:53:41.545675: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:53:41.546265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2022-04-07 01:53:41.546342: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-07 01:53:41.546366: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-07 01:53:41.546387: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-07 01:53:41.546405: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-07 01:53:41.546424: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-07 01:53:41.546453: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-07 01:53:41.546519: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-07 01:53:41.546603: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:53:41.547419: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:53:41.548184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2022-04-07 01:53:41.548270: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-07 01:53:41.549512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-04-07 01:53:41.549537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2022-04-07 01:53:41.549550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2022-04-07 01:53:41.549664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:53:41.550240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:53:41.550817: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-04-07 01:53:41.550857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "INFO:tensorflow:Restoring parameters from training/model.ckpt-500\n",
      "I0407 01:53:41.552493 140392554559360 saver.py:1284] Restoring parameters from training/model.ckpt-500\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "W0407 01:53:43.063070 140392554559360 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "2022-04-07 01:53:43.549537: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:53:43.550189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2022-04-07 01:53:43.550286: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-07 01:53:43.550312: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-07 01:53:43.550335: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-07 01:53:43.550356: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-07 01:53:43.550381: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-07 01:53:43.550402: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-07 01:53:43.550422: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-07 01:53:43.550515: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:53:43.551182: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:53:43.551726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2022-04-07 01:53:43.551767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-04-07 01:53:43.551780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2022-04-07 01:53:43.551790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2022-04-07 01:53:43.551905: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:53:43.552481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:53:43.552996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "INFO:tensorflow:Restoring parameters from training/model.ckpt-500\n",
      "I0407 01:53:43.554046 140392554559360 saver.py:1284] Restoring parameters from training/model.ckpt-500\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "W0407 01:53:44.110745 140392554559360 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "W0407 01:53:44.111013 140392554559360 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 324 variables.\n",
      "I0407 01:53:44.436209 140392554559360 graph_util_impl.py:334] Froze 324 variables.\n",
      "INFO:tensorflow:Converted 324 variables to const ops.\n",
      "I0407 01:53:44.504755 140392554559360 graph_util_impl.py:394] Converted 324 variables to const ops.\n",
      "2022-04-07 01:53:44.626843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:53:44.627543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2022-04-07 01:53:44.627645: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-07 01:53:44.627672: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-07 01:53:44.627700: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-07 01:53:44.627725: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-07 01:53:44.627751: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-07 01:53:44.627775: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-07 01:53:44.627800: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-07 01:53:44.627897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:53:44.628582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:53:44.629188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2022-04-07 01:53:44.629244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-04-07 01:53:44.629259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2022-04-07 01:53:44.629271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2022-04-07 01:53:44.629385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:53:44.630067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 01:53:44.630862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "W0407 01:53:45.146434 140392554559360 deprecation.py:323] From /content/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:No assets to save.\n",
      "I0407 01:53:45.147198 140392554559360 builder_impl.py:640] No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "I0407 01:53:45.147347 140392554559360 builder_impl.py:460] No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: ./fine_tuned_model/saved_model/saved_model.pb\n",
      "I0407 01:53:45.376241 140392554559360 builder_impl.py:425] SavedModel written to: ./fine_tuned_model/saved_model/saved_model.pb\n",
      "INFO:tensorflow:Writing pipeline config file to ./fine_tuned_model/pipeline.config\n",
      "I0407 01:53:45.394833 140392554559360 config_util.py:254] Writing pipeline config file to ./fine_tuned_model/pipeline.config\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "output_directory = './fine_tuned_model'\n",
    "\n",
    "lst = os.listdir(model_dir)\n",
    "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
    "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
    "last_model = lst[steps.argmax()].replace('.meta', '')\n",
    "\n",
    "last_model_path = os.path.join(model_dir, last_model)\n",
    "print(last_model_path)\n",
    "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
    "    --input_type=image_tensor \\\n",
    "    --pipeline_config_path={pipeline_fname} \\\n",
    "    --output_directory={output_directory} \\\n",
    "    --trained_checkpoint_prefix={last_model_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Me7XfMDQvuEn"
   },
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vIYcvA20vtzf",
    "outputId": "6830a086-3ccb-46c5-e386-9a04575a0c96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-07 02:00:37.948250: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-04-07 02:00:37.976989: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 02:00:37.977576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2022-04-07 02:00:37.977840: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-07 02:00:37.979828: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-07 02:00:37.980808: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-07 02:00:37.981102: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-07 02:00:37.984549: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-07 02:00:37.985798: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-07 02:00:37.989603: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-07 02:00:37.989703: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 02:00:37.990293: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 02:00:37.990799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2022-04-07 02:00:37.995929: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
      "2022-04-07 02:00:37.996260: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557a66723480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-04-07 02:00:37.996302: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-04-07 02:00:38.185431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 02:00:38.186195: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557a6ac90540 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-04-07 02:00:38.186227: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2022-04-07 02:00:38.186388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 02:00:38.186911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2022-04-07 02:00:38.186963: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-07 02:00:38.187001: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-07 02:00:38.187023: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-07 02:00:38.187044: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-07 02:00:38.187076: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-07 02:00:38.187094: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-07 02:00:38.187110: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-07 02:00:38.187177: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 02:00:38.187715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 02:00:38.188249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2022-04-07 02:00:38.188318: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-07 02:00:38.189293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-04-07 02:00:38.189318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2022-04-07 02:00:38.189330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2022-04-07 02:00:38.189436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 02:00:38.189986: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 02:00:38.190506: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-04-07 02:00:38.190588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "INFO:tensorflow:Reading input from 1 files\n",
      "I0407 02:00:38.191328 140040566036352 infer_detections.py:68] Reading input from 1 files\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/inference/detection_inference.py:35: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "W0407 02:00:38.191735 140040566036352 deprecation.py:323] From /content/models/research/object_detection/inference/detection_inference.py:35: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/input.py:277: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "W0407 02:00:38.196772 140040566036352 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/input.py:277: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "W0407 02:00:38.197033 140040566036352 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/input.py:112: RefVariable.count_up_to (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Dataset.range instead.\n",
      "W0407 02:00:38.199513 140040566036352 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/input.py:112: RefVariable.count_up_to (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Dataset.range instead.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/variables.py:2522: count_up_to (from tensorflow.python.ops.state_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Dataset.range instead.\n",
      "W0407 02:00:38.199661 140040566036352 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/variables.py:2522: count_up_to (from tensorflow.python.ops.state_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Dataset.range instead.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0407 02:00:38.201795 140040566036352 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0407 02:00:38.202628 140040566036352 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/inference/detection_inference.py:37: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "W0407 02:00:38.209894 140040566036352 deprecation.py:323] From /content/models/research/object_detection/inference/detection_inference.py:37: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "INFO:tensorflow:Reading graph and building model...\n",
      "I0407 02:00:38.248299 140040566036352 infer_detections.py:71] Reading graph and building model...\n",
      "INFO:tensorflow:Running inference and writing output to /content/detections.record\n",
      "I0407 02:00:38.644042 140040566036352 infer_detections.py:77] Running inference and writing output to /content/detections.record\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/inference/infer_detections.py:79: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0407 02:00:38.705748 140040566036352 deprecation.py:323] From /content/models/research/object_detection/inference/infer_detections.py:79: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Processed 0 images...\n",
      "I0407 02:00:38.706937 140040566036352 infer_detections.py:85] Processed 0 images...\n",
      "2022-04-07 02:00:39.810134: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-07 02:00:41.029611: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "INFO:tensorflow:Processed 10 images...\n",
      "I0407 02:00:42.525673 140040566036352 infer_detections.py:85] Processed 10 images...\n",
      "INFO:tensorflow:Processed 20 images...\n",
      "I0407 02:00:43.570062 140040566036352 infer_detections.py:85] Processed 20 images...\n",
      "INFO:tensorflow:Processed 30 images...\n",
      "I0407 02:00:45.337865 140040566036352 infer_detections.py:85] Processed 30 images...\n",
      "INFO:tensorflow:Processed 40 images...\n",
      "I0407 02:00:46.830351 140040566036352 infer_detections.py:85] Processed 40 images...\n",
      "INFO:tensorflow:Processed 50 images...\n",
      "I0407 02:00:48.325105 140040566036352 infer_detections.py:85] Processed 50 images...\n",
      "INFO:tensorflow:Processed 60 images...\n",
      "I0407 02:00:49.390369 140040566036352 infer_detections.py:85] Processed 60 images...\n",
      "INFO:tensorflow:Processed 70 images...\n",
      "I0407 02:00:50.543445 140040566036352 infer_detections.py:85] Processed 70 images...\n",
      "INFO:tensorflow:Processed 80 images...\n",
      "I0407 02:00:51.645129 140040566036352 infer_detections.py:85] Processed 80 images...\n",
      "INFO:tensorflow:Processed 90 images...\n",
      "I0407 02:00:53.091165 140040566036352 infer_detections.py:85] Processed 90 images...\n",
      "INFO:tensorflow:Processed 100 images...\n",
      "I0407 02:00:53.895277 140040566036352 infer_detections.py:85] Processed 100 images...\n",
      "INFO:tensorflow:Finished processing records\n",
      "I0407 02:00:53.913316 140040566036352 infer_detections.py:92] Finished processing records\n"
     ]
    }
   ],
   "source": [
    "!python /content/models/research/object_detection/inference/infer_detections.py --input_tfrecord_paths=/content/tensorflow-object-detection-faster-rcnn/data/test.record --output_tfrecord_path=/content/detections.record --inference_graph=/content/models/research/fine_tuned_model/frozen_inference_graph.pb --discard_image_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7VsMJmEqQICL",
    "outputId": "56f6729b-7943-4582-fb90-4541ed845bca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /content/cf3.py:145: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/cf3.py:38: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "W0407 02:00:57.302576 140056303228800 deprecation.py:323] From /content/cf3.py:38: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "Processed 100 images\n",
      "Processed 100 images\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0. 40.  7.]\n",
      " [ 0. 60.  4.]\n",
      " [ 0.  0.  0.]] \n",
      "\n",
      "[[ 0. 40.  7.]\n",
      " [ 0. 60.  4.]\n",
      " [ 0.  0.  0.]]\n",
      "0.0\n",
      "47.0\n",
      "/content/cf3.py:118: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  precision = float(confusion_matrix[id, id] / total_predicted)\n",
      "precision_Good@0.5IOU: nan\n",
      "recall_Good@0.5IOU: 0.00\n",
      "[[ 0. 40.  7.]\n",
      " [ 0. 60.  4.]\n",
      " [ 0.  0.  0.]]\n",
      "100.0\n",
      "64.0\n",
      "precision_Bad@0.5IOU: 0.60\n",
      "recall_Bad@0.5IOU: 0.94\n",
      "  category  ...  recall_@0.5IOU\n",
      "0     Good  ...          0.0000\n",
      "1      Bad  ...          0.9375\n",
      "\n",
      "[2 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "!python /content/cf3.py --detections_record=/content/detections.record --label_map=/content/tensorflow-object-detection-faster-rcnn/data/label_map.pbtxt --output_path=/content/confusion_matrix3.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "cvI1NKslwQHR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "wAggRg5NwRF6"
   },
   "outputs": [],
   "source": [
    "pdf=pd.DataFrame(columns=['score', 'label_idx', 'left', 'top', 'right', 'bottom', 'by', 'filename'])\n",
    "example = tf.train.Example()\n",
    "for record in tf.compat.v1.io.tf_record_iterator('/content/detections.record'):\n",
    "    example.ParseFromString(record)\n",
    "    f = example.features.feature\n",
    "    score = f['image/detection/score'].float_list.value\n",
    "    score = [x for x in score if x >= 0.20]\n",
    "    l = len(score)\n",
    "    pdf=pdf.append({'score': score,\n",
    "                    'label_idx': f['image/detection/label'].int64_list.value[:l],\n",
    "                    'left': f['image/detection/bbox/xmin'].float_list.value[:l],\n",
    "                    'top': f['image/detection/bbox/ymin'].float_list.value[:l],\n",
    "                    'right': f['image/detection/bbox/xmax'].float_list.value[:l],\n",
    "                    'bottom': f['image/detection/bbox/ymax'].float_list.value[:l],\n",
    "                    'filename': f['image/filename'].bytes_list.value[0].decode()}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "id": "S3aiYcpwwfj8",
    "outputId": "8c37fa1c-9a57-4f86-d7c4-3db97669d161"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-d85144c9-9b35-4872-9661-dc2131d6db3a\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>label_idx</th>\n",
       "      <th>left</th>\n",
       "      <th>top</th>\n",
       "      <th>right</th>\n",
       "      <th>bottom</th>\n",
       "      <th>by</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.5410347580909729, 0.4609178304672241, 0.405...</td>\n",
       "      <td>[2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 2, 2, 1, ...</td>\n",
       "      <td>[0.01421847939491272, 0.025623351335525513, 0....</td>\n",
       "      <td>[0.01005101203918457, 0.020071029663085938, 0....</td>\n",
       "      <td>[0.9864640235900879, 0.9768209457397461, 0.481...</td>\n",
       "      <td>[0.9880973696708679, 0.9808790683746338, 0.918...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.5410341620445251, 0.460918128490448, 0.4050...</td>\n",
       "      <td>[2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 2, 2, 1, ...</td>\n",
       "      <td>[0.014218300580978394, 0.025623470544815063, 0...</td>\n",
       "      <td>[0.010051161050796509, 0.020070910453796387, 0...</td>\n",
       "      <td>[0.9864636659622192, 0.9768211841583252, 0.481...</td>\n",
       "      <td>[0.9880971908569336, 0.9808790683746338, 0.918...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.5410335063934326, 0.46091800928115845, 0.40...</td>\n",
       "      <td>[2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 2, 2, 1, ...</td>\n",
       "      <td>[0.014218270778656006, 0.025623589754104614, 0...</td>\n",
       "      <td>[0.010050922632217407, 0.020070791244506836, 0...</td>\n",
       "      <td>[0.9864636063575745, 0.9768208265304565, 0.481...</td>\n",
       "      <td>[0.988097071647644, 0.9808793067932129, 0.9189...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.5410363674163818, 0.46091583371162415, 0.40...</td>\n",
       "      <td>[2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 2, 2, 1, ...</td>\n",
       "      <td>[0.01421821117401123, 0.02562326192855835, 0.0...</td>\n",
       "      <td>[0.010051220655441284, 0.020071029663085938, 0...</td>\n",
       "      <td>[0.9864637851715088, 0.9768211245536804, 0.481...</td>\n",
       "      <td>[0.9880973100662231, 0.9808790683746338, 0.918...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.5410357713699341, 0.4609159529209137, 0.405...</td>\n",
       "      <td>[2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 2, 2, 1, ...</td>\n",
       "      <td>[0.014218240976333618, 0.02562326192855835, 0....</td>\n",
       "      <td>[0.010051161050796509, 0.020071029663085938, 0...</td>\n",
       "      <td>[0.9864639043807983, 0.9768211245536804, 0.481...</td>\n",
       "      <td>[0.9880973100662231, 0.9808790683746338, 0.918...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d85144c9-9b35-4872-9661-dc2131d6db3a')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-d85144c9-9b35-4872-9661-dc2131d6db3a button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-d85144c9-9b35-4872-9661-dc2131d6db3a');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                               score  \\\n",
       "0  [0.5410347580909729, 0.4609178304672241, 0.405...   \n",
       "1  [0.5410341620445251, 0.460918128490448, 0.4050...   \n",
       "2  [0.5410335063934326, 0.46091800928115845, 0.40...   \n",
       "3  [0.5410363674163818, 0.46091583371162415, 0.40...   \n",
       "4  [0.5410357713699341, 0.4609159529209137, 0.405...   \n",
       "\n",
       "                                           label_idx  \\\n",
       "0  [2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 2, 2, 1, ...   \n",
       "1  [2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 2, 2, 1, ...   \n",
       "2  [2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 2, 2, 1, ...   \n",
       "3  [2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 2, 2, 1, ...   \n",
       "4  [2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 1, 2, 2, 1, ...   \n",
       "\n",
       "                                                left  \\\n",
       "0  [0.01421847939491272, 0.025623351335525513, 0....   \n",
       "1  [0.014218300580978394, 0.025623470544815063, 0...   \n",
       "2  [0.014218270778656006, 0.025623589754104614, 0...   \n",
       "3  [0.01421821117401123, 0.02562326192855835, 0.0...   \n",
       "4  [0.014218240976333618, 0.02562326192855835, 0....   \n",
       "\n",
       "                                                 top  \\\n",
       "0  [0.01005101203918457, 0.020071029663085938, 0....   \n",
       "1  [0.010051161050796509, 0.020070910453796387, 0...   \n",
       "2  [0.010050922632217407, 0.020070791244506836, 0...   \n",
       "3  [0.010051220655441284, 0.020071029663085938, 0...   \n",
       "4  [0.010051161050796509, 0.020071029663085938, 0...   \n",
       "\n",
       "                                               right  \\\n",
       "0  [0.9864640235900879, 0.9768209457397461, 0.481...   \n",
       "1  [0.9864636659622192, 0.9768211841583252, 0.481...   \n",
       "2  [0.9864636063575745, 0.9768208265304565, 0.481...   \n",
       "3  [0.9864637851715088, 0.9768211245536804, 0.481...   \n",
       "4  [0.9864639043807983, 0.9768211245536804, 0.481...   \n",
       "\n",
       "                                              bottom   by filename  \n",
       "0  [0.9880973696708679, 0.9808790683746338, 0.918...  NaN    1.png  \n",
       "1  [0.9880971908569336, 0.9808790683746338, 0.918...  NaN   10.png  \n",
       "2  [0.988097071647644, 0.9808793067932129, 0.9189...  NaN  100.png  \n",
       "3  [0.9880973100662231, 0.9808790683746338, 0.918...  NaN   11.png  \n",
       "4  [0.9880973100662231, 0.9808790683746338, 0.918...  NaN   12.png  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wF2Xej7uwrUn",
    "outputId": "0ead703e-137d-4ab9-a4ab-29b01dafcbb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Kwu7jxsBx01L"
   },
   "outputs": [],
   "source": [
    "pdf.to_csv('/content/Detections.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kp2b0wSWlm94",
    "outputId": "084762bb-b6f2-4ed8-f3ad-f63af0d644d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: content/models/research/fine_tuned_model/ (stored 0%)\n",
      "  adding: content/models/research/fine_tuned_model/pipeline.config (deflated 70%)\n",
      "  adding: content/models/research/fine_tuned_model/frozen_inference_graph.pb (deflated 10%)\n",
      "  adding: content/models/research/fine_tuned_model/checkpoint (deflated 42%)\n",
      "  adding: content/models/research/fine_tuned_model/eval_0/ (stored 0%)\n",
      "  adding: content/models/research/fine_tuned_model/eval_0/pipeline.config (deflated 70%)\n",
      "  adding: content/models/research/fine_tuned_model/eval_0/events.out.tfevents.1649296460.525be702b579 (deflated 11%)\n",
      "  adding: content/models/research/fine_tuned_model/model.ckpt.meta (deflated 93%)\n",
      "  adding: content/models/research/fine_tuned_model/model.ckpt.index (deflated 68%)\n",
      "  adding: content/models/research/fine_tuned_model/saved_model/ (stored 0%)\n",
      "  adding: content/models/research/fine_tuned_model/saved_model/variables/ (stored 0%)\n",
      "  adding: content/models/research/fine_tuned_model/saved_model/saved_model.pb (deflated 10%)\n",
      "  adding: content/models/research/fine_tuned_model/model.ckpt.data-00000-of-00001 (deflated 7%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r /content/models.zip /content/models/research/fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NNwDekUpmT7m",
    "outputId": "60e17cee-70d0-4891-9cb5-451278e7583c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: content/models/research/training/ (stored 0%)\n",
      "  adding: content/models/research/training/model.ckpt-0.meta (deflated 93%)\n",
      "  adding: content/models/research/training/model.ckpt-500.meta (deflated 93%)\n",
      "  adding: content/models/research/training/model.ckpt-0.data-00000-of-00001 (deflated 55%)\n",
      "  adding: content/models/research/training/graph.pbtxt (deflated 97%)\n",
      "  adding: content/models/research/training/checkpoint (deflated 59%)\n",
      "  adding: content/models/research/training/events.out.tfevents.1649295290.525be702b579 (deflated 93%)\n",
      "  adding: content/models/research/training/eval_0/ (stored 0%)\n",
      "  adding: content/models/research/training/eval_0/events.out.tfevents.1649295691.525be702b579 (deflated 35%)\n",
      "  adding: content/models/research/training/eval_1/ (stored 0%)\n",
      "  adding: content/models/research/training/eval_1/pipeline.config (deflated 67%)\n",
      "  adding: content/models/research/training/eval_1/events.out.tfevents.1649295723.525be702b579 (deflated 11%)\n",
      "  adding: content/models/research/training/model.ckpt-500.data-00000-of-00001 (deflated 8%)\n",
      "  adding: content/models/research/training/model.ckpt-500.index (deflated 72%)\n",
      "  adding: content/models/research/training/model.ckpt-0.index (deflated 79%)\n",
      "  adding: content/models/research/training/export/ (stored 0%)\n",
      "  adding: content/models/research/training/export/Servo/ (stored 0%)\n",
      "  adding: content/models/research/training/export/Servo/1649295692/ (stored 0%)\n",
      "  adding: content/models/research/training/export/Servo/1649295692/variables/ (stored 0%)\n",
      "  adding: content/models/research/training/export/Servo/1649295692/variables/variables.index (deflated 68%)\n",
      "  adding: content/models/research/training/export/Servo/1649295692/variables/variables.data-00000-of-00001 (deflated 7%)\n",
      "  adding: content/models/research/training/export/Servo/1649295692/saved_model.pb (deflated 93%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r /content/trainvalandtest.zip /content/models/research/training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "rrVnzykwmkEh",
    "outputId": "be2c2a5e-0267-4cf6-d344-60aa4b2f3ea6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/MyDrive/SSD/trainvalandtest.zip'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "shutil.move(\"/content/models.zip\", \"/content/drive/MyDrive/SSD\")\n",
    "shutil.move(\"/content/trainvalandtest.zip\", \"/content/drive/MyDrive/SSD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HyX7BN4KZtxc"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v0VWtgHFeTE1"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir /content/models/research/training"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SSD_TF1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
